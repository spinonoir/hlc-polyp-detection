{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colonoscopy Polyp Detection w/FCOS and Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from src.LightningModuleFCOS import LightningModuleFCOS as pl_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = dict (\n",
    "    project = \"hlc-polyp-detection\",\n",
    "    architecture = \"fcos_resnet50_fpn\",\n",
    "    dataset_id = \"hlc-custom-polyp-detection\",\n",
    "    infra = \"osx\",\n",
    "    num_classes = 2,\n",
    "    max_epochs = 100,\n",
    "    lr=0.01,\n",
    "    min_lr=0.0000001,\n",
    "    epochs=15,\n",
    "    batch_size=4,\n",
    "    nesterov=True,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005,\n",
    "    clip_limit=0.25,\n",
    "    difference=False,\n",
    "    name=\"fancy_walrus\"\n",
    ")\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"models/fcos_resnet50_fpn\")\n",
    "LOG_DIR = os.path.join(ROOT_DIR, \"log\")\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "INPUT_SIZE = 1024\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 12\n",
    "\n",
    "wandb_key = Path(os.path.join(ROOT_DIR, \"wandb.txt\")).read_text().strip()\n",
    "os.environ[\"WANDB_API_KEY\"] = wandb_key\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = os.path.join(ROOT_DIR, \"LightningFCOS-polyps.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"infra\"] == \"paperspace\":\n",
    "    # !pip install -r alubumentations pytorch-lightning wandb --upgrade\n",
    "    import wandb\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def wandb_context(configuration=CONFIG):\n",
    "    run = wandb.init(reinit=True, config=configuration, project=CONFIG['project'])\n",
    "    try:\n",
    "        yield run\n",
    "    finally:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.PolypsPLDataModule import PolypsPLDataModule\n",
    "\n",
    "polyp_dm = PolypsPLDataModule(data_dir='./data', batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping\n",
    "\n",
    "def train_model(model, run_name, dm=None, run=None):\n",
    "    wandb_logger = None\n",
    "    if run is not None:\n",
    "        run.config[\"train_run_name\"] = run_name\n",
    "\n",
    "        from pytorch_lightning.loggers import WandbLogger\n",
    "        wandb_logger = WandbLogger()\n",
    "    \n",
    "    chkpt = ModelCheckpoint(\n",
    "        dirpath=os.path.join(MODEL_DIR, \"chkpts\"),\n",
    "        filename=f\"{CONFIG['name']}-chkpt-{run_name}\",\n",
    "        monitor=\"val_recall\",\n",
    "        mode=\"max\")\n",
    "    \n",
    "    lrnrate = LearningRateMonitor(logging_interval=\"step\", log_momentum=True)\n",
    "\n",
    "    earlystop = EarlyStopping(\n",
    "        monitor=\"val_recall\",\n",
    "        patience=50,\n",
    "        verbose=True,\n",
    "        mode=\"max\")\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "        logger=wandb_logger,\n",
    "        callbacks=[chkpt, lrnrate, earlystop],\n",
    "        log_every_n_steps=1,\n",
    "        max_epochs=CONFIG[\"max_epochs\"])\n",
    "    \n",
    "    trainer.fit(\n",
    "        model,\n",
    "        datamodule=dm)\n",
    "    \n",
    "    return pl_module.load_from_checkpoint(chkpt.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/hlc-polyp-detection/FCOS_polyp_detection/wandb/run-20230507_014337-r0r2dodt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/r0r2dodt' target=\"_blank\">chocolate-thunder-104</a></strong> to <a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection' target=\"_blank\">https://wandb.ai/hidden-layer-cake/hlc-polyp-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/r0r2dodt' target=\"_blank\">https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/r0r2dodt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type | Params\n",
      "----------------------------------\n",
      "0 | detector | FCOS | 32.1 M\n",
      "----------------------------------\n",
      "32.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "32.1 M    Total params\n",
      "128.258   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: adjusting learning rate of group 0 to 1.0000e-02.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c24ede7a66480ea1ccbf67acf09e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e3c89cbfb4402d99921163166e7ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-SGD</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-SGD-momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bbox_ctrness</td><td>nan</td></tr><tr><td>bbox_regression</td><td>nan</td></tr><tr><td>classification</td><td>nan</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>lr-SGD</td><td>0.01</td></tr><tr><td>lr-SGD-momentum</td><td>0.9</td></tr><tr><td>train_loss</td><td>nan</td></tr><tr><td>trainer/global_step</td><td>6699</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">chocolate-thunder-104</strong> at: <a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/r0r2dodt' target=\"_blank\">https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/r0r2dodt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 5 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230507_014337-r0r2dodt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/notebooks/hlc-polyp-detection/FCOS_polyp_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jarret/Desktop/CSCI 566 - Deep Learning and Its Applications/HLC - 566 Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb Cell 11\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m run\u001b[39m.\u001b[39mwatch(model)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mfull_train()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model \u001b[39m=\u001b[39m train_model(model, run_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfull\u001b[39;49m\u001b[39m\"\u001b[39;49m, dm\u001b[39m=\u001b[39;49mpolyp_dm, run\u001b[39m=\u001b[39;49mrun)\n",
      "\u001b[1;32m/Users/jarret/Desktop/CSCI 566 - Deep Learning and Its Applications/HLC - 566 Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb Cell 11\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     logger\u001b[39m=\u001b[39mwandb_logger,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     callbacks\u001b[39m=\u001b[39m[chkpt, lrnrate, earlystop],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     log_every_n_steps\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39mCONFIG[\u001b[39m\"\u001b[39m\u001b[39mmax_epochs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m trainer\u001b[39m.\u001b[39mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     datamodule\u001b[39m=\u001b[39mdm)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/FCOS_polyp_detection/LightningFCOS-polys.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pl_module\u001b[39m.\u001b[39;49mload_from_checkpoint(chkpt\u001b[39m.\u001b[39;49mbest_model_path)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pytorch_lightning/core/module.py:1531\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1453\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1459\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:\n\u001b[1;32m   1460\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m \u001b[39m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m \u001b[39m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[39m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1531\u001b[0m     loaded \u001b[39m=\u001b[39m _load_from_checkpoint(\n\u001b[1;32m   1532\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m   1533\u001b[0m         checkpoint_path,\n\u001b[1;32m   1534\u001b[0m         map_location,\n\u001b[1;32m   1535\u001b[0m         hparams_file,\n\u001b[1;32m   1536\u001b[0m         strict,\n\u001b[1;32m   1537\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1538\u001b[0m     )\n\u001b[1;32m   1539\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pytorch_lightning/core/saving.py:60\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_from_checkpoint\u001b[39m(\n\u001b[1;32m     52\u001b[0m     \u001b[39mcls\u001b[39m: Union[Type[\u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m], Type[\u001b[39m\"\u001b[39m\u001b[39mpl.LightningDataModule\u001b[39m\u001b[39m\"\u001b[39m]],\n\u001b[1;32m     53\u001b[0m     checkpoint_path: Union[_PATH, IO],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     58\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[\u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpl.LightningDataModule\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     59\u001b[0m     \u001b[39mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m---> 60\u001b[0m         checkpoint \u001b[39m=\u001b[39m pl_load(checkpoint_path, map_location\u001b[39m=\u001b[39;49mmap_location)\n\u001b[1;32m     62\u001b[0m     \u001b[39m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     checkpoint \u001b[39m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[1;32m     64\u001b[0m         checkpoint, checkpoint_path\u001b[39m=\u001b[39m(checkpoint_path \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(checkpoint_path, (\u001b[39mstr\u001b[39m, Path)) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     65\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/lightning_fabric/utilities/cloud_io.py:50\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mhub\u001b[39m.\u001b[39mload_state_dict_from_url(\n\u001b[1;32m     46\u001b[0m         \u001b[39mstr\u001b[39m(path_or_url),\n\u001b[1;32m     47\u001b[0m         map_location\u001b[39m=\u001b[39mmap_location,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m fs \u001b[39m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 50\u001b[0m \u001b[39mwith\u001b[39;00m fs\u001b[39m.\u001b[39;49mopen(path_or_url, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mload(f, map_location\u001b[39m=\u001b[39mmap_location)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fsspec/spec.py:1135\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1134\u001b[0m     ac \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautocommit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrans)\n\u001b[0;32m-> 1135\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(\n\u001b[1;32m   1136\u001b[0m         path,\n\u001b[1;32m   1137\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   1138\u001b[0m         block_size\u001b[39m=\u001b[39;49mblock_size,\n\u001b[1;32m   1139\u001b[0m         autocommit\u001b[39m=\u001b[39;49mac,\n\u001b[1;32m   1140\u001b[0m         cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[1;32m   1141\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1142\u001b[0m     )\n\u001b[1;32m   1143\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1144\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mfsspec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompression\u001b[39;00m \u001b[39mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fsspec/implementations/local.py:183\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_mkdir \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fsspec/implementations/local.py:285\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    284\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fsspec/implementations/local.py:290\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf\u001b[39m.\u001b[39mclosed:\n\u001b[1;32m    289\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocommit \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[0;32m--> 290\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    291\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression:\n\u001b[1;32m    292\u001b[0m             compress \u001b[39m=\u001b[39m compr[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression]\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/notebooks/hlc-polyp-detection/FCOS_polyp_detection'"
     ]
    }
   ],
   "source": [
    "# this should have been:\n",
    "# with wandb_context(CONFIG) as run:\n",
    "#     model = LightningFasterModule()\n",
    "from src.LightningModuleFCOS import LightningModuleFCOS as pl_module\n",
    "with wandb_context() as run:\n",
    "    model = pl_module(CONFIG)\n",
    "    if run is not None:\n",
    "        # watch the hyperparameters and gradients of the model \n",
    "        run.watch(model)\n",
    "        model.full_train()\n",
    "        model = train_model(model, run_name=\"full\", dm=polyp_dm, run=run)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
