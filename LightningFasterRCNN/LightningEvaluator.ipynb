{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch \n",
    "import wandb\n",
    "\n",
    "CONFIG = dict (\n",
    "    project = \"hlc-polyp-detection\",\n",
    "    architecture = \"fasterrcnn_resnext50_32x4d\",\n",
    "    dataset_id = \"hlc-custom-polyp-detection\",\n",
    "    infra = \"osx\",\n",
    "    num_classes = 2,\n",
    "    max_epochs = 100,\n",
    "    lr=0.01,\n",
    "    min_lr=0.0000001,\n",
    "    epochs=15,\n",
    "    batch_size=4,\n",
    "    nesterov=True,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005,\n",
    "    clip_limit=0.25,\n",
    "    difference=False,\n",
    "    name=\"fancy_walrus\"\n",
    ")\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"model\")\n",
    "LOG_DIR = os.path.join(ROOT_DIR, \"log\")\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "INPUT_SIZE = 1024\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "wandb_key = Path(os.path.join(ROOT_DIR, \"wandb.txt\")).read_text().strip()\n",
    "os.environ[\"WANDB_API_KEY\"] = wandb_key\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = os.path.join(ROOT_DIR, \"LightningFastRCNN-polyps.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarret/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/utilities/migration/utils.py:49: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.0.2, which is newer than your current Lightning version: v1.9.3\n",
      "  rank_zero_warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mspinonoir\u001b[0m (\u001b[33mhidden-layer-cake\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230507_001944-mkrjae57</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/mkrjae57' target=\"_blank\">royal-flower-108</a></strong> to <a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection' target=\"_blank\">https://wandb.ai/hidden-layer-cake/hlc-polyp-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/mkrjae57' target=\"_blank\">https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/mkrjae57</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/jarret/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "from src.PolypsPLDataModule import PolypsPLDataModule\n",
    "from src.LightningFasterModule import LightningFasterModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# Initialize the data module\n",
    "polyp_dm = PolypsPLDataModule(data_dir='./data', batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "# Load the model from the checkpoint\n",
    "model = LightningFasterModule.load_from_checkpoint(os.path.join(MODEL_DIR, \"peppered_jaguar-chkpt-full.ckpt\"))\n",
    "\n",
    "# Initialize the WandB logger\n",
    "wandb_logger = WandbLogger(project=CONFIG['project'], log_model=\"all\")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    logger=wandb_logger,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else None,\n",
    "    log_every_n_steps=1\n",
    ")\n",
    "\n",
    "# Run the test set\n",
    "# trainer.test(model, datamodule=polyp_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ece8b742f354e59917f2fee52184d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.598007082939148     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_avg_f1        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6866459846496582     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_avg_precision     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7771739363670349     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_avg_recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6622670888900757     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6866463422775269     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_max_f1        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_max_precision     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_max_recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_min_f1        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_min_precision     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_min_recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7771736979484558     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6622670888900757     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.598007082939148    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_avg_f1       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6866459846496582    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_avg_precision    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7771739363670349    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_avg_recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6622670888900757    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6866463422775269    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_max_f1       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_max_precision    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_max_recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_min_f1       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_min_precision    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_min_recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7771736979484558    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6622670888900757    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.598007082939148,\n",
       "  'test_precision': 0.7771736979484558,\n",
       "  'test_recall': 0.6622670888900757,\n",
       "  'test_f1': 0.6866463422775269,\n",
       "  'test_max_precision': 1.0,\n",
       "  'test_max_recall': 1.0,\n",
       "  'test_max_f1': 1.0,\n",
       "  'test_min_precision': 0.0,\n",
       "  'test_min_recall': 0.0,\n",
       "  'test_min_f1': 0.0,\n",
       "  'test_avg_precision': 0.7771739363670349,\n",
       "  'test_avg_recall': 0.6622670888900757,\n",
       "  'test_avg_f1': 0.6866459846496582}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.PolypsPLDataModule import PolypsPLDataModule\n",
    "from src.LightningFasterModule import LightningFasterModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# Initialize the data module\n",
    "polyp_dm = PolypsPLDataModule(data_dir='./data', batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "# Load the model from the checkpoint\n",
    "model = LightningFasterModule.load_from_checkpoint(os.path.join(MODEL_DIR, \"lazy_panda-chkpt-full.ckpt\"))\n",
    "\n",
    "# Initialize the WandB logger\n",
    "wandb_logger = WandbLogger(project=CONFIG['project'], log_model=\"all\")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    logger=wandb_logger,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else None,\n",
    "    log_every_n_steps=1\n",
    ")\n",
    "\n",
    "# Run the test set\n",
    "# trainer.test(model, datamodule=polyp_dm)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_sum = pl.utilities.model_summary.summarize(model, max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   | Name                                       | Type                     | Params\n",
       "-----------------------------------------------------------------------------------------\n",
       "0  | detector                                   | FasterRCNN               | 43.3 M\n",
       "1  | detector.transform                         | GeneralizedRCNNTransform | 0     \n",
       "2  | detector.backbone                          | BackboneWithFPN          | 26.9 M\n",
       "3  | detector.backbone.body                     | IntermediateLayerGetter  | 23.5 M\n",
       "4  | detector.backbone.body.conv1               | Conv2d                   | 9.4 K \n",
       "5  | detector.backbone.body.bn1                 | BatchNorm2d              | 128   \n",
       "6  | detector.backbone.body.relu                | ReLU                     | 0     \n",
       "7  | detector.backbone.body.maxpool             | MaxPool2d                | 0     \n",
       "8  | detector.backbone.body.layer1              | Sequential               | 215 K \n",
       "9  | detector.backbone.body.layer2              | Sequential               | 1.2 M \n",
       "10 | detector.backbone.body.layer3              | Sequential               | 7.1 M \n",
       "11 | detector.backbone.body.layer4              | Sequential               | 15.0 M\n",
       "12 | detector.backbone.fpn                      | FeaturePyramidNetwork    | 3.3 M \n",
       "13 | detector.backbone.fpn.inner_blocks         | ModuleList               | 985 K \n",
       "14 | detector.backbone.fpn.layer_blocks         | ModuleList               | 2.4 M \n",
       "15 | detector.backbone.fpn.extra_blocks         | LastLevelMaxPool         | 0     \n",
       "16 | detector.rpn                               | RegionProposalNetwork    | 1.2 M \n",
       "17 | detector.rpn.anchor_generator              | AnchorGenerator          | 0     \n",
       "18 | detector.rpn.head                          | RPNHead                  | 1.2 M \n",
       "19 | detector.rpn.head.conv                     | Sequential               | 1.2 M \n",
       "20 | detector.rpn.head.cls_logits               | Conv2d                   | 771   \n",
       "21 | detector.rpn.head.bbox_pred                | Conv2d                   | 3.1 K \n",
       "22 | detector.roi_heads                         | RoIHeads                 | 15.2 M\n",
       "23 | detector.roi_heads.box_roi_pool            | MultiScaleRoIAlign       | 0     \n",
       "24 | detector.roi_heads.box_head                | FastRCNNConvFCHead       | 15.2 M\n",
       "25 | detector.roi_heads.box_head.0              | Conv2dNormActivation     | 590 K \n",
       "26 | detector.roi_heads.box_head.1              | Conv2dNormActivation     | 590 K \n",
       "27 | detector.roi_heads.box_head.2              | Conv2dNormActivation     | 590 K \n",
       "28 | detector.roi_heads.box_head.3              | Conv2dNormActivation     | 590 K \n",
       "29 | detector.roi_heads.box_head.4              | Flatten                  | 0     \n",
       "30 | detector.roi_heads.box_head.5              | Linear                   | 12.8 M\n",
       "31 | detector.roi_heads.box_head.6              | ReLU                     | 0     \n",
       "32 | detector.roi_heads.box_predictor           | FastRCNNPredictor        | 10.2 K\n",
       "33 | detector.roi_heads.box_predictor.cls_score | Linear                   | 2.0 K \n",
       "34 | detector.roi_heads.box_predictor.bbox_pred | Linear                   | 8.2 K \n",
       "-----------------------------------------------------------------------------------------\n",
       "43.3 M    Trainable params\n",
       "0         Non-trainable params\n",
       "43.3 M    Total params\n",
       "173.025   Total estimated model params size (MB)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mos_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not ModelSummary",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jarret/Desktop/CSCI 566 - Deep Learning and Its Applications/HLC - 566 Project/hlc-polyp-detection/LightningFasterRCNN/LightningEvaluator.ipynb Cell 5\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/LightningFasterRCNN/LightningEvaluator.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# write mos to file\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/LightningFasterRCNN/LightningEvaluator.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(MODEL_DIR, \u001b[39m\"\u001b[39m\u001b[39mmodel_summary.txt\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jarret/Desktop/CSCI%20566%20-%20Deep%20Learning%20and%20Its%20Applications/HLC%20-%20566%20Project/hlc-polyp-detection/LightningFasterRCNN/LightningEvaluator.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     f\u001b[39m.\u001b[39;49mwrite(mos_sum)\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not ModelSummary"
     ]
    }
   ],
   "source": [
    "\n",
    "# write mos to file\n",
    "with open(os.path.join(MODEL_DIR, \"model_summary.txt\"), \"w\") as f:\n",
    "    f.write(mos_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
