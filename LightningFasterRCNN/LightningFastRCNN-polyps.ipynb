{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colonoscopy Polyp Detection w/Faster R-CNN and Lightning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = dict (\n",
    "    project = \"hlc-polyp-detection\",\n",
    "    architecture = \"fasterrcnn_resnext50_32x4d\",\n",
    "    dataset_id = \"hlc-custom-polyp-detection\",\n",
    "    infra = \"osx\",\n",
    "    num_classes = 2,\n",
    "    max_epochs = 100,\n",
    "    lr=0.01,\n",
    "    min_lr=0.0000001,\n",
    "    epochs=15,\n",
    "    batch_size=4,\n",
    "    nesterov=True,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005,\n",
    "    clip_limit=0.25,\n",
    "    difference=False,\n",
    "    name=\"fancy_walrus\"\n",
    ")\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"model\")\n",
    "LOG_DIR = os.path.join(ROOT_DIR, \"log\")\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "INPUT_SIZE = 1024\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "wandb_key = Path(os.path.join(ROOT_DIR, \"wandb.txt\")).read_text().strip()\n",
    "os.environ[\"WANDB_API_KEY\"] = wandb_key\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = os.path.join(ROOT_DIR, \"LightningFastRCNN-polyps.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"infra\"] == \"paperspace\":\n",
    "    # !pip install -r alubumentations pytorch-lightning wandb --upgrade\n",
    "    import wandb\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def wandb_context(configuration=CONFIG):\n",
    "    run = wandb.init(reinit=True, config=configuration, project=CONFIG['project'])\n",
    "    try:\n",
    "        yield run\n",
    "    finally:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.PolypsPLDataModule import PolypsPLDataModule\n",
    "\n",
    "polyp_dm = PolypsPLDataModule(data_dir='./data', batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping\n",
    "\n",
    "def train_model(model, run_name, dm=None, run=None):\n",
    "    wandb_logger = None\n",
    "    if run is not None:\n",
    "        run.config[\"train_run_name\"] = run_name\n",
    "\n",
    "        from pytorch_lightning.loggers import WandbLogger\n",
    "        wandb_logger = WandbLogger()\n",
    "    \n",
    "    chkpt = ModelCheckpoint(\n",
    "        dirpath=os.path.join(MODEL_DIR, \"chkpts\"),\n",
    "        filename=f\"{CONFIG['name']}-chkpt-{run_name}\",\n",
    "        monitor=\"val_recall\",\n",
    "        mode=\"max\")\n",
    "    \n",
    "    lrnrate = LearningRateMonitor(logging_interval=\"step\", log_momentum=True)\n",
    "\n",
    "    earlystop = EarlyStopping(\n",
    "        monitor=\"val_recall\",\n",
    "        patience=50,\n",
    "        verbose=True,\n",
    "        mode=\"max\")\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "        logger=wandb_logger,\n",
    "        callbacks=[chkpt, lrnrate, earlystop],\n",
    "        log_every_n_steps=1,\n",
    "        max_epochs=CONFIG[\"max_epochs\"])\n",
    "    \n",
    "    trainer.fit(\n",
    "        model,\n",
    "        datamodule=dm)\n",
    "    \n",
    "    return LightningFasterModule.load_from_checkpoint(chkpt.best_model_path)\n",
    "\n",
    "list(sorted(glob.glob(os.path.join(root_dir, \"*\", stage, \"images\", \"*.[jp][pn]g\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.LightningFasterModule import LightningFasterModule\n",
    "# this should have been:\n",
    "# with wandb_context(CONFIG) as run:\n",
    "#     model = LightningFasterModule()\n",
    "with wandb_context() as run:\n",
    "    model = LightningFasterModule(CONFIG)\n",
    "    if run is not None:\n",
    "        # watch the hyperparameters and gradients of the model \n",
    "        run.watch(model)\n",
    "    # trained_model = train_model(model, run_name=\"head\", dm=polyp_dm, run=run)\n",
    "\n",
    "    model.full_train()\n",
    "    model = train_model(model, run_name=\"full\", dm=polyp_dm, run=run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.LightningFasterModule import LightningFasterModule\n",
    "\n",
    "with wandb_context() as run:\n",
    "    model = LightningFasterModule(CONFIG)\n",
    "    if run is not None:\n",
    "        run.watch(model)\n",
    "    # model.load_from_checkpoint(checkpoint_path=os.path.join(CONFIG.checkpoint_dir, \"best_\n",
    "\n",
    "    # trained_model = train_model(model, run_name=\"head\", dm=polyp_dm, run=run)\n",
    "    # model = test_model(model, run_name=\"test_run\", dm=polyp_dm, run=run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hidden-layer-cake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
