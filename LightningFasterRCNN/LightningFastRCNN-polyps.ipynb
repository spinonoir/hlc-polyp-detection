{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colonoscopy Polyp Detection w/Faster R-CNN and Lightning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = dict (\n",
    "    project = \"hlc-polyp-detection\",\n",
    "    architecture = \"fasterrcnn_resnext50_32x4d\",\n",
    "    dataset_id = \"hlc-custom-polyp-detection\",\n",
    "    infra = \"osx\",\n",
    "    num_classes = 2,\n",
    "    lr=0.01,\n",
    "    min_lr=0.0000001,\n",
    "    epochs=15,\n",
    "    batch_size=4,\n",
    "    nesterov=True,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005,\n",
    "    clip_limit=0.25,\n",
    "    difference=False,\n",
    ")\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"model\")\n",
    "LOG_DIR = os.path.join(ROOT_DIR, \"log\")\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "INPUT_SIZE = 800\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "wandb_key = Path(os.path.join(ROOT_DIR, \"wandb.txt\")).read_text().strip()\n",
    "os.environ[\"WANDB_API_KEY\"] = wandb_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"infra\"] == \"paperspace\":\n",
    "    !pip install -r alubumentations pytorch-lightning wandb --upgrade\n",
    "    import wandb\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def wandb_context(configuration=CONFIG):\n",
    "    run = wandb.init(reinit=True, config=configuration, project=CONFIG['project'])\n",
    "    try:\n",
    "        yield run\n",
    "    finally:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.PolypsPLDataModule import PolypsPLDataModule\n",
    "\n",
    "polyp_dm = PolypsPLDataModule(data_dir=DATA_DIR, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "def train_model(model, run_name, dm=None, run=None):\n",
    "    wandb_logger = None\n",
    "    if run is not None:\n",
    "        run.config[\"train_run_name\"] = run_name\n",
    "\n",
    "        from pytorch_lightning.loggers import WandbLogger\n",
    "        wandb_logger = WandbLogger()\n",
    "    \n",
    "    chkpt = ModelCheckpoint(\n",
    "        dirpath=os.path.join(MODEL_DIR, \"checkpoints\"),\n",
    "        filename=f\"chkpt-{run_name}\",\n",
    "        monitor=\"val_recall\",\n",
    "        mode=\"max\")\n",
    "    \n",
    "    trainer = Trainer(gpus=1, logger=wandb_logger, callbacks=[chkpt]) if DEVICE == \"cuda\" else Trainer(accelerator=\"cpu\", logger=wandb_logger, callbacks=[chkpt])\n",
    "    trainer.fit(\n",
    "        model,\n",
    "        datamodule=dm)\n",
    "    \n",
    "    return LightningFasterModule.load_from_checkpoint(chkpt.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jarret/Desktop/CSCI 566 - Deep Learning and Its Applications/HLC - 566 Project/hlc-polyp-detection/LightningFasterRCNN/wandb/run-20230502_174317-acbwuod3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/acbwuod3' target=\"_blank\">gentle-firebrand-34</a></strong> to <a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection' target=\"_blank\">https://wandb.ai/hidden-layer-cake/hlc-polyp-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/acbwuod3' target=\"_blank\">https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/acbwuod3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarret/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/jarret/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "/Users/jarret/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | detector | FasterRCNN | 43.3 M\n",
      "----------------------------------------\n",
      "43.0 M    Trainable params\n",
      "225 K     Non-trainable params\n",
      "43.3 M    Total params\n",
      "173.025   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: adjusting learning rate of group 0 to 1.0000e-02.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63095787dfc140a4ad2e587492484f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN VALIDATION STEP\n",
      "type(targets)=<class 'tuple'> type(pred_boxes)=<class 'list'>\n",
      "pred_boxes=[{'boxes': tensor([[0.0000e+00, 0.0000e+00, 6.3554e+02, 7.2572e+02],\n",
      "        [6.2482e+02, 4.3144e+02, 6.4298e+02, 4.7503e+02],\n",
      "        [1.6064e+02, 2.9829e+02, 3.8609e+02, 5.2213e+02],\n",
      "        [1.5455e+02, 3.6195e+02, 6.5928e+02, 7.9700e+02],\n",
      "        [3.7735e+02, 5.5647e+02, 5.1888e+02, 5.9885e+02],\n",
      "        [9.7314e+01, 3.0929e+02, 3.5015e+02, 5.9012e+02],\n",
      "        [3.1212e+02, 6.4413e+02, 3.8753e+02, 7.2184e+02],\n",
      "        [1.5536e+02, 2.8107e+02, 3.1475e+02, 3.7091e+02],\n",
      "        [5.6991e+02, 4.0497e+02, 6.0948e+02, 4.4935e+02],\n",
      "        [2.8840e+02, 6.1680e+02, 4.0556e+02, 7.3888e+02],\n",
      "        [2.3704e+02, 3.7959e+02, 2.8094e+02, 4.7032e+02],\n",
      "        [2.8269e+02, 5.3860e+02, 4.0512e+02, 7.1697e+02],\n",
      "        [2.7192e+02, 5.3787e+02, 5.4549e+02, 6.1348e+02],\n",
      "        [1.5601e+02, 2.8373e+02, 2.5231e+02, 4.6804e+02],\n",
      "        [6.2832e+02, 2.5529e+02, 6.9471e+02, 3.1191e+02],\n",
      "        [1.9076e+02, 2.7859e+02, 3.2447e+02, 3.1382e+02],\n",
      "        [1.8331e+02, 3.2556e+02, 7.2448e+02, 5.4062e+02],\n",
      "        [3.3399e+02, 8.9058e+01, 4.9424e+02, 2.6355e+02],\n",
      "        [1.5818e+02, 2.8093e+02, 2.2732e+02, 3.5105e+02],\n",
      "        [4.7164e+02, 5.1339e+02, 5.7662e+02, 5.7166e+02],\n",
      "        [1.8488e+02, 2.7361e+02, 5.1601e+02, 6.2989e+02],\n",
      "        [1.8445e+02, 4.8970e+02, 2.0871e+02, 5.3330e+02],\n",
      "        [2.6648e+02, 2.9463e+02, 3.7016e+02, 4.9947e+02],\n",
      "        [2.9399e+02, 5.5603e+01, 4.7009e+02, 3.3927e+02],\n",
      "        [4.9411e+02, 5.3843e+02, 5.7839e+02, 7.0358e+02],\n",
      "        [6.8590e-02, 7.9551e+02, 7.1539e+00, 8.0000e+02],\n",
      "        [2.7311e+02, 2.9102e+02, 5.7837e+02, 5.6312e+02],\n",
      "        [1.6324e+02, 1.6769e+02, 2.8250e+02, 2.8631e+02],\n",
      "        [5.1285e+02, 5.8958e+02, 5.6783e+02, 7.0768e+02],\n",
      "        [5.6884e+02, 4.0006e+02, 6.1371e+02, 5.2322e+02],\n",
      "        [8.4560e+01, 2.2674e+02, 3.1941e+02, 4.7150e+02],\n",
      "        [2.3122e+02, 2.8666e+02, 3.5756e+02, 3.1907e+02],\n",
      "        [9.6037e-02, 7.9253e+02, 6.5837e+00, 7.9824e+02],\n",
      "        [2.9181e-01, 7.9554e+02, 1.9924e+01, 7.9976e+02],\n",
      "        [1.7534e+02, 2.8264e+02, 2.5945e+02, 3.6163e+02],\n",
      "        [1.7496e+02, 2.7186e+02, 3.0074e+02, 3.0533e+02],\n",
      "        [1.6124e+02, 3.0659e+02, 2.2690e+02, 3.9318e+02],\n",
      "        [1.4668e+02, 2.9606e+02, 2.1055e+02, 3.7877e+02],\n",
      "        [3.7332e+02, 5.3626e+02, 5.1596e+02, 5.8488e+02],\n",
      "        [1.7201e+02, 2.5449e+02, 2.8853e+02, 2.9020e+02],\n",
      "        [1.9034e+02, 2.8498e+02, 3.1335e+02, 3.4112e+02],\n",
      "        [1.1034e-01, 0.0000e+00, 8.6824e+00, 6.0915e+02],\n",
      "        [1.4238e+02, 2.8813e+02, 1.8857e+02, 4.1334e+02],\n",
      "        [1.9997e+02, 1.7161e+02, 7.7597e+02, 7.5089e+02],\n",
      "        [5.0567e+02, 6.2205e+01, 7.4890e+02, 2.4102e+02],\n",
      "        [1.2603e+02, 2.7790e+02, 2.3609e+02, 4.0524e+02],\n",
      "        [4.4774e+02, 2.0022e+02, 6.1036e+02, 3.2993e+02],\n",
      "        [6.5791e+02, 4.5452e+02, 6.8721e+02, 5.1264e+02],\n",
      "        [3.1213e+02, 4.8723e+02, 5.7148e+02, 5.6982e+02],\n",
      "        [5.7538e+02, 4.7438e+02, 5.9593e+02, 5.2057e+02],\n",
      "        [1.1759e-01, 6.3715e+02, 4.2490e+00, 8.0000e+02],\n",
      "        [4.9966e-02, 2.5322e+02, 2.0306e+00, 6.7759e+02],\n",
      "        [5.5636e+02, 2.5278e+02, 7.1890e+02, 3.3940e+02],\n",
      "        [7.6615e-02, 4.4820e+02, 2.3648e+00, 8.0000e+02],\n",
      "        [3.1604e+02, 5.9414e+02, 4.5148e+02, 7.3019e+02],\n",
      "        [5.3233e+02, 5.9588e+02, 5.6191e+02, 6.5198e+02],\n",
      "        [2.7872e+02, 1.4828e+02, 3.4372e+02, 2.6786e+02],\n",
      "        [5.3052e+02, 1.6099e+02, 6.9740e+02, 2.4285e+02],\n",
      "        [1.7157e+02, 2.8536e+02, 3.9304e+02, 3.9448e+02],\n",
      "        [5.4289e+02, 5.8835e+02, 5.6724e+02, 6.3766e+02],\n",
      "        [6.6373e+02, 3.9966e+02, 6.8475e+02, 4.5284e+02],\n",
      "        [5.2242e+02, 8.9987e+01, 6.2153e+02, 2.2987e+02],\n",
      "        [4.8016e-01, 3.4347e+02, 1.0877e+01, 8.0000e+02],\n",
      "        [2.9678e+00, 7.9504e+02, 3.0216e+01, 7.9918e+02],\n",
      "        [1.5113e+02, 2.4733e+02, 1.7424e+02, 2.8741e+02],\n",
      "        [3.2861e+02, 6.9496e+01, 4.4063e+02, 1.9952e+02],\n",
      "        [4.2036e+02, 7.5898e+01, 5.4504e+02, 2.0034e+02],\n",
      "        [1.4942e+02, 2.0989e+02, 4.4541e+02, 4.8850e+02],\n",
      "        [6.3802e+02, 4.5521e+02, 6.9468e+02, 5.2295e+02],\n",
      "        [6.5428e+02, 3.9180e+02, 6.9206e+02, 5.0043e+02],\n",
      "        [2.0033e-01, 7.7677e+02, 7.5271e+00, 7.9555e+02],\n",
      "        [2.8377e+02, 9.7941e+01, 3.6703e+02, 2.7405e+02],\n",
      "        [2.2936e-01, 0.0000e+00, 1.8437e+00, 5.8996e+02],\n",
      "        [2.7533e+00, 7.9336e+02, 1.7675e+01, 7.9833e+02],\n",
      "        [2.5079e+02, 8.0211e+01, 3.4491e+02, 2.5507e+02],\n",
      "        [4.9864e+02, 1.8516e+02, 7.0443e+02, 3.4414e+02],\n",
      "        [5.2378e+02, 1.4851e+02, 5.9521e+02, 2.0402e+02],\n",
      "        [1.6352e-01, 0.0000e+00, 2.5824e+00, 2.9853e+02],\n",
      "        [5.8548e+02, 4.7365e+02, 6.0470e+02, 5.1684e+02],\n",
      "        [5.2840e+02, 5.8716e+02, 5.7119e+02, 6.7260e+02],\n",
      "        [5.8009e+02, 9.1670e+01, 6.0154e+02, 1.2172e+02],\n",
      "        [7.1798e-01, 1.9495e+02, 2.6817e+00, 6.7545e+02],\n",
      "        [2.8687e+02, 4.3195e+01, 5.2797e+02, 2.3675e+02],\n",
      "        [3.0125e+02, 7.9796e+02, 7.0043e+02, 8.0000e+02],\n",
      "        [2.6647e-01, 6.8802e+02, 6.1796e+00, 7.9388e+02],\n",
      "        [1.8075e+02, 2.0883e+02, 2.6348e+02, 2.8771e+02],\n",
      "        [5.8064e+02, 4.5312e+02, 6.0264e+02, 5.1641e+02],\n",
      "        [4.6350e+02, 2.4539e+02, 5.8810e+02, 3.4152e+02],\n",
      "        [5.9291e+02, 1.9637e+02, 7.0315e+02, 3.3729e+02],\n",
      "        [6.5063e+02, 2.6276e+02, 7.0744e+02, 3.2355e+02],\n",
      "        [3.5167e+02, 5.6005e+02, 5.9858e+02, 7.6581e+02],\n",
      "        [6.0250e+02, 1.7402e+02, 7.1114e+02, 2.3777e+02],\n",
      "        [1.2915e+02, 2.3618e+02, 2.2023e+02, 4.7602e+02],\n",
      "        [1.0229e+02, 5.8811e+01, 3.4680e+02, 2.7892e+02],\n",
      "        [5.6124e+02, 4.3308e+02, 6.0037e+02, 5.3239e+02],\n",
      "        [1.8338e+02, 4.7768e+02, 2.8340e+02, 6.7010e+02],\n",
      "        [4.7856e+02, 7.1626e+01, 5.9251e+02, 2.2609e+02],\n",
      "        [3.6509e+02, 1.7857e+02, 5.0071e+02, 3.4853e+02],\n",
      "        [1.3716e+00, 2.2597e+02, 4.1969e+01, 5.0034e+02],\n",
      "        [3.9138e+02, 2.5258e+02, 7.5055e+02, 5.7104e+02]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.6041, 0.5939, 0.5733, 0.5593, 0.5386, 0.5380, 0.5339, 0.5306, 0.5282,\n",
      "        0.5269, 0.5213, 0.5208, 0.5140, 0.5129, 0.5052, 0.5046, 0.4989, 0.4974,\n",
      "        0.4950, 0.4944, 0.4932, 0.4927, 0.4924, 0.4903, 0.4849, 0.4832, 0.4792,\n",
      "        0.4780, 0.4768, 0.4733, 0.4732, 0.4712, 0.4703, 0.4675, 0.4664, 0.4650,\n",
      "        0.4636, 0.4599, 0.4593, 0.4571, 0.4568, 0.4563, 0.4554, 0.4553, 0.4548,\n",
      "        0.4502, 0.4501, 0.4472, 0.4461, 0.4447, 0.4443, 0.4441, 0.4408, 0.4385,\n",
      "        0.4352, 0.4327, 0.4325, 0.4306, 0.4244, 0.4234, 0.4200, 0.4199, 0.4189,\n",
      "        0.4180, 0.4176, 0.4157, 0.4141, 0.4133, 0.4126, 0.4114, 0.4104, 0.4099,\n",
      "        0.4087, 0.4065, 0.4042, 0.4027, 0.4024, 0.4011, 0.3999, 0.3993, 0.3988,\n",
      "        0.3987, 0.3978, 0.3964, 0.3927, 0.3911, 0.3910, 0.3895, 0.3843, 0.3840,\n",
      "        0.3839, 0.3810, 0.3752, 0.3747, 0.3740, 0.3714, 0.3709, 0.3705, 0.3695,\n",
      "        0.3694])}, {'boxes': tensor([[3.5372e+02, 2.3259e+02, 5.9793e+02, 6.0675e+02],\n",
      "        [3.0270e+02, 3.8567e+02, 5.8533e+02, 6.7068e+02],\n",
      "        [3.1593e+02, 6.4636e+02, 3.7909e+02, 7.1142e+02],\n",
      "        [3.9442e+02, 3.8597e+02, 5.9727e+02, 5.4707e+02],\n",
      "        [3.9458e+02, 4.5333e+02, 6.5886e+02, 6.7987e+02],\n",
      "        [3.6035e+01, 0.0000e+00, 7.1049e+02, 7.2871e+02],\n",
      "        [3.5142e+02, 3.8479e+02, 4.7439e+02, 5.1306e+02],\n",
      "        [3.7628e+02, 3.0823e+02, 4.6354e+02, 3.8704e+02],\n",
      "        [3.9901e+02, 3.3868e+02, 4.7699e+02, 3.9888e+02],\n",
      "        [3.5319e+02, 2.7582e+02, 4.8562e+02, 4.0266e+02],\n",
      "        [2.8951e+02, 3.1402e+02, 3.4837e+02, 3.7596e+02],\n",
      "        [3.9026e+02, 3.8949e+02, 5.2447e+02, 4.3103e+02],\n",
      "        [4.2733e+02, 4.6986e+02, 5.8198e+02, 6.6293e+02],\n",
      "        [3.8414e+02, 3.7562e+02, 5.0843e+02, 4.1362e+02],\n",
      "        [3.4629e+02, 3.8072e+02, 4.3727e+02, 5.7266e+02],\n",
      "        [3.4473e+02, 3.8428e+02, 5.8551e+02, 4.8055e+02],\n",
      "        [5.1733e+02, 4.2453e+02, 5.8128e+02, 4.9305e+02],\n",
      "        [2.1380e+02, 1.5155e+02, 3.3434e+02, 2.7582e+02],\n",
      "        [5.9076e+02, 5.1119e+02, 7.0610e+02, 6.2813e+02],\n",
      "        [6.4853e+02, 4.0848e+02, 6.9670e+02, 5.2198e+02],\n",
      "        [4.4694e+02, 5.5109e+02, 5.7210e+02, 6.6422e+02],\n",
      "        [4.3831e+02, 3.2243e+02, 6.7029e+02, 6.5099e+02],\n",
      "        [2.8379e+02, 3.5172e+02, 6.4509e+02, 5.4390e+02],\n",
      "        [5.8801e+02, 5.5517e+02, 6.7844e+02, 6.2766e+02],\n",
      "        [5.8184e+02, 2.0540e+02, 6.4953e+02, 2.6832e+02],\n",
      "        [3.0305e+02, 1.0319e+02, 5.0658e+02, 4.1119e+02],\n",
      "        [3.2632e+02, 2.2455e+02, 4.6775e+02, 3.9222e+02],\n",
      "        [3.6057e+02, 3.2735e+02, 5.1000e+02, 4.0796e+02],\n",
      "        [3.6264e+02, 3.8531e+02, 4.8994e+02, 6.1478e+02],\n",
      "        [3.0743e+02, 3.2395e+02, 3.7202e+02, 3.8621e+02],\n",
      "        [6.9755e-02, 7.9232e+02, 5.3371e+00, 7.9822e+02],\n",
      "        [5.7835e-02, 7.9521e+02, 5.5540e+00, 8.0000e+02],\n",
      "        [2.3298e+02, 1.6829e+02, 3.5585e+02, 3.7711e+02],\n",
      "        [3.0054e+02, 6.1426e+02, 4.2085e+02, 7.3086e+02],\n",
      "        [6.7590e+02, 3.1004e+02, 7.1670e+02, 3.4968e+02],\n",
      "        [5.2614e+02, 4.2621e+02, 5.8610e+02, 5.4781e+02],\n",
      "        [3.0782e+02, 2.0888e+02, 5.2656e+02, 7.0810e+02],\n",
      "        [1.6989e-01, 7.9525e+02, 1.6023e+01, 7.9979e+02],\n",
      "        [5.7949e+02, 8.0406e+01, 7.0345e+02, 2.7385e+02],\n",
      "        [3.4555e+02, 4.1013e+02, 3.8502e+02, 5.5665e+02],\n",
      "        [1.7444e+02, 3.6748e+02, 3.5692e+02, 5.3319e+02],\n",
      "        [5.6516e+02, 2.7081e+02, 7.2397e+02, 4.0609e+02],\n",
      "        [5.5755e+02, 6.0735e+02, 6.1525e+02, 6.5913e+02],\n",
      "        [2.8889e+02, 3.8281e+02, 3.5401e+02, 5.0529e+02],\n",
      "        [1.8366e-01, 2.3123e+02, 7.8408e+00, 8.0000e+02],\n",
      "        [5.4844e-02, 3.9442e+02, 1.8494e+00, 8.0000e+02],\n",
      "        [2.6868e+02, 4.3721e+02, 3.4249e+02, 5.1077e+02],\n",
      "        [2.1552e+02, 3.1303e+02, 3.6647e+02, 4.9390e+02],\n",
      "        [6.0677e+02, 1.2254e+02, 7.2988e+02, 2.9240e+02],\n",
      "        [5.7604e+01, 4.5611e+01, 3.6445e+02, 5.5301e+02],\n",
      "        [3.2554e+02, 5.2654e+02, 4.6974e+02, 6.8250e+02],\n",
      "        [3.7113e+02, 3.6335e+02, 4.9088e+02, 4.0511e+02],\n",
      "        [6.5148e+02, 4.5103e+02, 7.1013e+02, 5.2291e+02],\n",
      "        [6.6838e+02, 2.6035e+02, 7.1566e+02, 2.9805e+02],\n",
      "        [3.5735e+02, 4.1703e+02, 4.1443e+02, 5.5466e+02],\n",
      "        [1.5920e+00, 7.9347e+02, 1.4123e+01, 7.9864e+02],\n",
      "        [4.8850e+02, 8.1547e+01, 7.4005e+02, 2.9798e+02],\n",
      "        [2.2737e-01, 0.0000e+00, 9.5760e+00, 5.4405e+02],\n",
      "        [8.9906e-02, 5.7958e+02, 3.0377e+00, 8.0000e+02],\n",
      "        [1.7913e+02, 1.8813e+02, 2.3690e+02, 2.8579e+02],\n",
      "        [4.6406e+02, 4.0368e+02, 5.9130e+02, 6.2611e+02],\n",
      "        [2.0088e+02, 4.5731e+02, 3.6870e+02, 5.7568e+02],\n",
      "        [4.9355e+02, 5.2950e+02, 6.0787e+02, 6.5232e+02],\n",
      "        [5.3737e+02, 5.5410e+02, 6.1049e+02, 6.3479e+02],\n",
      "        [2.8199e+02, 4.7526e+02, 3.5981e+02, 5.5389e+02],\n",
      "        [5.6846e+02, 1.8054e+02, 7.1605e+02, 2.8908e+02],\n",
      "        [3.4148e+02, 3.5091e+02, 5.6238e+02, 4.2763e+02],\n",
      "        [3.2551e+02, 3.9926e+02, 3.6963e+02, 5.3264e+02],\n",
      "        [3.2482e+02, 3.6461e+02, 4.0739e+02, 5.6723e+02],\n",
      "        [6.3929e-02, 1.9495e+02, 1.9939e+00, 6.5434e+02],\n",
      "        [6.3171e+02, 2.5883e+02, 7.1860e+02, 3.0293e+02],\n",
      "        [6.6943e+02, 3.1742e+02, 7.1770e+02, 3.7349e+02],\n",
      "        [1.2007e+02, 2.9783e+02, 6.2756e+02, 7.9779e+02],\n",
      "        [3.8424e+02, 7.9792e+02, 7.4728e+02, 8.0000e+02],\n",
      "        [4.2299e-01, 6.1721e+02, 5.1493e+00, 8.0000e+02],\n",
      "        [2.5861e+02, 4.0064e+02, 3.7168e+02, 5.6603e+02],\n",
      "        [1.0330e+02, 7.6783e+01, 3.2783e+02, 2.8381e+02],\n",
      "        [5.6322e-01, 4.0773e+02, 1.2494e+01, 8.0000e+02],\n",
      "        [3.0043e+02, 3.3029e+02, 3.8976e+02, 5.3722e+02],\n",
      "        [3.5365e+02, 2.6041e+02, 4.5411e+02, 5.3920e+02],\n",
      "        [1.2703e+02, 1.4880e+02, 3.2515e+02, 6.6650e+02],\n",
      "        [1.5430e+02, 4.1393e+02, 5.5969e+02, 6.1089e+02],\n",
      "        [4.1350e+02, 8.1667e+01, 5.8972e+02, 3.7587e+02],\n",
      "        [6.0048e+02, 2.4216e+02, 7.1435e+02, 2.9422e+02],\n",
      "        [2.5479e-01, 7.7817e+02, 7.4416e+00, 7.9531e+02],\n",
      "        [6.4880e+02, 3.1910e+02, 7.1946e+02, 4.1790e+02],\n",
      "        [2.3055e+02, 1.6602e+02, 3.0977e+02, 2.5002e+02],\n",
      "        [1.6421e+02, 4.2133e+02, 3.2654e+02, 5.6880e+02],\n",
      "        [6.7357e-02, 0.0000e+00, 2.8432e+00, 2.3252e+02],\n",
      "        [6.5466e+02, 2.8149e+02, 7.1589e+02, 3.4552e+02],\n",
      "        [4.9301e-02, 2.3318e+00, 1.7884e+00, 4.8577e+02],\n",
      "        [2.9770e+00, 7.9383e+02, 2.9107e+01, 7.9935e+02],\n",
      "        [3.1882e+00, 7.9478e+02, 1.0884e+01, 7.9999e+02],\n",
      "        [3.1405e+02, 3.5457e+02, 3.6869e+02, 4.9216e+02],\n",
      "        [5.1920e+02, 6.8557e+01, 6.3775e+02, 2.4385e+02],\n",
      "        [7.3755e-01, 3.0288e+01, 2.4025e+01, 8.0000e+02],\n",
      "        [6.0700e+02, 4.0949e+02, 7.2250e+02, 6.2669e+02],\n",
      "        [6.2955e+02, 2.0189e+02, 7.1949e+02, 2.8194e+02],\n",
      "        [6.4406e+02, 3.0248e+02, 7.1429e+02, 3.7935e+02],\n",
      "        [2.7824e-01, 6.9645e+02, 6.6847e+00, 7.9307e+02]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.6509, 0.6162, 0.6103, 0.5886, 0.5707, 0.5687, 0.5683, 0.5544, 0.5433,\n",
      "        0.5391, 0.5350, 0.5337, 0.5261, 0.5240, 0.5117, 0.5113, 0.5020, 0.4979,\n",
      "        0.4954, 0.4942, 0.4903, 0.4854, 0.4825, 0.4822, 0.4813, 0.4813, 0.4805,\n",
      "        0.4800, 0.4781, 0.4769, 0.4765, 0.4751, 0.4748, 0.4724, 0.4697, 0.4680,\n",
      "        0.4660, 0.4651, 0.4647, 0.4641, 0.4641, 0.4640, 0.4629, 0.4627, 0.4590,\n",
      "        0.4565, 0.4534, 0.4532, 0.4529, 0.4528, 0.4526, 0.4466, 0.4438, 0.4425,\n",
      "        0.4424, 0.4406, 0.4398, 0.4383, 0.4382, 0.4359, 0.4350, 0.4323, 0.4292,\n",
      "        0.4286, 0.4284, 0.4277, 0.4267, 0.4265, 0.4245, 0.4225, 0.4208, 0.4197,\n",
      "        0.4175, 0.4146, 0.4144, 0.4131, 0.4130, 0.4104, 0.4093, 0.4091, 0.4068,\n",
      "        0.4040, 0.4026, 0.4019, 0.4008, 0.3986, 0.3966, 0.3963, 0.3949, 0.3930,\n",
      "        0.3930, 0.3909, 0.3895, 0.3854, 0.3838, 0.3827, 0.3813, 0.3806, 0.3799,\n",
      "        0.3795])}, {'boxes': tensor([[3.4475e+02, 2.1604e+02, 5.9941e+02, 5.8154e+02],\n",
      "        [3.5758e+02, 3.4491e+02, 5.6777e+02, 5.3019e+02],\n",
      "        [3.1621e+02, 6.4445e+02, 3.8158e+02, 7.1222e+02],\n",
      "        [4.0767e+02, 5.1494e+02, 4.3287e+02, 5.3939e+02],\n",
      "        [2.8840e+02, 6.1878e+02, 4.0444e+02, 7.3581e+02],\n",
      "        [3.8408e+02, 3.9993e+02, 5.4699e+02, 6.0249e+02],\n",
      "        [2.7035e+02, 2.2140e+02, 3.0170e+02, 2.5630e+02],\n",
      "        [3.8192e+02, 3.5762e+02, 6.0932e+02, 6.5713e+02],\n",
      "        [0.0000e+00, 4.7938e-01, 2.0353e+01, 6.5472e+00],\n",
      "        [3.6889e+02, 2.9256e+02, 4.7640e+02, 3.4709e+02],\n",
      "        [3.3719e+02, 3.4744e+02, 5.7330e+02, 4.4101e+02],\n",
      "        [2.3380e+02, 1.3284e+02, 3.3640e+02, 1.8867e+02],\n",
      "        [3.5653e+02, 3.3286e+02, 4.6259e+02, 5.3227e+02],\n",
      "        [3.8465e+02, 3.3676e+02, 5.2141e+02, 3.7368e+02],\n",
      "        [1.9314e+02, 1.4076e+02, 2.4219e+02, 2.2631e+02],\n",
      "        [3.0923e+02, 2.8611e+02, 5.6026e+02, 7.2971e+02],\n",
      "        [3.6756e+02, 3.4872e+02, 4.9524e+02, 3.9594e+02],\n",
      "        [3.4185e+02, 3.5095e+02, 3.8999e+02, 4.9052e+02],\n",
      "        [0.0000e+00, 4.8819e-01, 6.2065e+01, 6.4216e+00],\n",
      "        [4.1160e+02, 3.3278e+02, 5.8138e+02, 4.7964e+02],\n",
      "        [2.0747e+02, 1.1152e+02, 3.3144e+02, 2.4189e+02],\n",
      "        [1.3411e-02, 7.9507e+02, 4.9904e+00, 8.0000e+02],\n",
      "        [3.5342e+02, 2.8251e+02, 5.1063e+02, 3.6078e+02],\n",
      "        [3.8051e+02, 3.1770e+02, 5.0283e+02, 3.5526e+02],\n",
      "        [1.6044e+02, 3.8909e+02, 3.5824e+02, 5.2003e+02],\n",
      "        [3.3463e-02, 7.9220e+02, 4.9381e+00, 7.9835e+02],\n",
      "        [5.6976e-02, 1.3196e+01, 3.9812e+00, 5.8876e+01],\n",
      "        [4.9704e+02, 1.6484e+02, 5.4899e+02, 2.5762e+02],\n",
      "        [5.3335e+02, 4.4883e+02, 6.9496e+02, 6.0301e+02],\n",
      "        [7.2987e-02, 7.9525e+02, 1.5407e+01, 7.9983e+02],\n",
      "        [5.1407e+02, 3.8230e+02, 5.7900e+02, 4.5646e+02],\n",
      "        [2.0765e+01, 0.0000e+00, 7.7154e+02, 7.3595e+02],\n",
      "        [1.4289e+00, 7.9330e+02, 1.3820e+01, 7.9856e+02],\n",
      "        [6.2985e+02, 3.6426e+02, 6.7621e+02, 4.7863e+02],\n",
      "        [4.4674e+02, 3.5397e+02, 5.7978e+02, 5.8831e+02],\n",
      "        [1.9818e+02, 7.5946e+01, 3.7004e+02, 3.4942e+02],\n",
      "        [6.7310e-02, 3.7540e+02, 1.9444e+00, 8.0000e+02],\n",
      "        [3.5818e+02, 2.7040e+02, 4.3294e+02, 3.4260e+02],\n",
      "        [1.7164e+00, 7.8671e+02, 9.9877e+00, 7.9842e+02],\n",
      "        [1.7463e-01, 0.0000e+00, 1.1299e+01, 4.3498e+02],\n",
      "        [2.9689e+02, 3.2544e+02, 3.5616e+02, 4.5143e+02],\n",
      "        [4.3705e+02, 2.8603e+02, 6.6500e+02, 6.2760e+02],\n",
      "        [2.0279e-01, 1.4032e+02, 7.2778e+00, 8.0000e+02],\n",
      "        [3.3473e+02, 3.5903e+02, 3.6730e+02, 4.9972e+02],\n",
      "        [3.5343e+02, 2.2810e+02, 4.7630e+02, 3.4821e+02],\n",
      "        [1.4671e+02, 3.5099e+02, 5.4716e+02, 5.5559e+02],\n",
      "        [2.8137e+02, 1.6657e+02, 3.3971e+02, 3.0163e+02],\n",
      "        [5.4882e+02, 2.3820e+02, 7.2018e+02, 3.7431e+02],\n",
      "        [3.2388e+02, 1.3151e+02, 4.4567e+02, 3.5033e+02],\n",
      "        [2.3941e+02, 3.6967e+02, 3.6919e+02, 5.0808e+02],\n",
      "        [2.0311e+02, 1.2541e+02, 2.6061e+02, 2.3361e+02],\n",
      "        [2.7084e+02, 4.0672e+02, 3.5152e+02, 4.8954e+02],\n",
      "        [5.5591e+02, 5.7029e+02, 6.2468e+02, 6.3057e+02],\n",
      "        [4.7800e+02, 5.8163e+02, 6.2034e+02, 7.1909e+02],\n",
      "        [3.6062e-01, 3.6798e+02, 1.1041e+01, 8.0000e+02],\n",
      "        [4.3165e+02, 4.9111e+02, 5.5985e+02, 6.1849e+02],\n",
      "        [3.3056e+02, 3.2513e+02, 3.8259e+02, 4.5551e+02],\n",
      "        [2.4033e+02, 9.8631e+01, 4.0585e+02, 4.5648e+02],\n",
      "        [4.4974e-02, 0.0000e+00, 4.1268e+00, 1.2415e+02],\n",
      "        [5.9335e+02, 6.5738e+01, 7.0151e+02, 2.4622e+02],\n",
      "        [5.3389e+02, 3.7277e+02, 7.3639e+02, 5.8755e+02],\n",
      "        [9.9499e-02, 5.5075e+02, 2.8068e+00, 8.0000e+02],\n",
      "        [5.5531e+02, 5.5918e+02, 6.6311e+02, 6.1447e+02],\n",
      "        [5.6926e+02, 1.7621e+02, 7.2918e+02, 2.6176e+02],\n",
      "        [5.4753e-02, 1.5343e+02, 2.0239e+00, 6.0445e+02],\n",
      "        [3.7840e+02, 7.9800e+02, 6.8398e+02, 8.0000e+02],\n",
      "        [5.1027e+02, 6.7266e+01, 7.3863e+02, 2.4604e+02],\n",
      "        [4.1448e+02, 8.4598e+01, 5.8416e+02, 3.5862e+02],\n",
      "        [3.0779e+00, 7.9465e+02, 1.1027e+01, 8.0000e+02],\n",
      "        [5.3298e+02, 4.7719e+02, 5.9961e+02, 6.0175e+02],\n",
      "        [3.0732e+02, 3.0076e+02, 3.8731e+02, 4.9943e+02],\n",
      "        [6.1483e+02, 1.6943e+02, 7.0386e+02, 2.5182e+02],\n",
      "        [2.3847e+02, 1.8343e+02, 3.0838e+02, 2.5893e+02],\n",
      "        [2.3359e+02, 1.3169e+02, 3.6300e+02, 2.9100e+02],\n",
      "        [5.2736e+02, 5.3805e+02, 6.4803e+02, 6.4379e+02],\n",
      "        [2.5352e+02, 2.9345e+02, 3.7452e+02, 4.4805e+02],\n",
      "        [5.7223e+02, 4.9565e+02, 7.1096e+02, 5.9219e+02],\n",
      "        [3.2712e+02, 3.2732e+02, 4.0927e+02, 5.4330e+02],\n",
      "        [2.9204e-01, 0.0000e+00, 3.2681e+00, 2.2433e+02],\n",
      "        [1.7991e+02, 9.6620e+01, 2.5702e+02, 3.6628e+02],\n",
      "        [4.9892e+00, 7.9417e+02, 3.0737e+01, 7.9942e+02],\n",
      "        [4.9709e+02, 5.0166e+02, 6.1585e+02, 6.0958e+02],\n",
      "        [4.9174e+02, 5.9371e+02, 6.1434e+02, 6.4432e+02],\n",
      "        [3.2813e+02, 7.6570e+01, 4.8304e+02, 2.9509e+02],\n",
      "        [2.3007e+02, 8.5263e+01, 3.0503e+02, 1.5124e+02],\n",
      "        [5.6660e+02, 2.0267e+02, 6.6802e+02, 2.5503e+02],\n",
      "        [1.5911e-01, 6.2796e+02, 4.9709e+00, 8.0000e+02],\n",
      "        [5.9446e+02, 2.1013e+02, 7.1671e+02, 2.6352e+02],\n",
      "        [1.0451e+02, 3.7210e+02, 5.5114e+02, 7.1431e+02],\n",
      "        [1.5235e+02, 4.4111e+02, 3.5274e+02, 5.5177e+02],\n",
      "        [3.4963e-01, 0.0000e+00, 2.1889e+00, 4.9696e+02],\n",
      "        [5.7604e+02, 1.8237e+02, 6.4668e+02, 2.4302e+02],\n",
      "        [4.7555e+02, 5.6971e+02, 6.4613e+02, 6.5685e+02],\n",
      "        [2.4257e-01, 7.0223e+02, 7.6029e+00, 7.9186e+02],\n",
      "        [5.1589e+02, 5.3955e+02, 6.1890e+02, 5.9762e+02],\n",
      "        [4.1276e+02, 3.4083e+02, 7.1291e+02, 5.2069e+02],\n",
      "        [2.5792e+02, 5.1379e+01, 5.0864e+02, 3.5209e+02],\n",
      "        [7.8882e+02, 7.9506e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [5.0739e+01, 7.8024e-01, 3.7671e+02, 7.1047e+02],\n",
      "        [1.4694e+00, 0.0000e+00, 2.9042e+01, 7.1380e+02]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.6097, 0.6015, 0.5941, 0.5889, 0.5769, 0.5682, 0.5645, 0.5627, 0.5498,\n",
      "        0.5377, 0.5223, 0.5171, 0.5157, 0.5104, 0.5030, 0.5019, 0.5007, 0.4970,\n",
      "        0.4902, 0.4898, 0.4875, 0.4803, 0.4802, 0.4800, 0.4790, 0.4729, 0.4690,\n",
      "        0.4680, 0.4653, 0.4643, 0.4638, 0.4631, 0.4620, 0.4606, 0.4584, 0.4577,\n",
      "        0.4559, 0.4547, 0.4486, 0.4481, 0.4478, 0.4476, 0.4465, 0.4463, 0.4462,\n",
      "        0.4450, 0.4442, 0.4420, 0.4406, 0.4390, 0.4382, 0.4380, 0.4378, 0.4364,\n",
      "        0.4364, 0.4352, 0.4350, 0.4324, 0.4290, 0.4287, 0.4281, 0.4251, 0.4250,\n",
      "        0.4234, 0.4228, 0.4219, 0.4193, 0.4171, 0.4164, 0.4142, 0.4137, 0.4137,\n",
      "        0.4135, 0.4114, 0.4108, 0.4091, 0.4089, 0.4084, 0.4084, 0.4070, 0.4030,\n",
      "        0.4016, 0.3996, 0.3989, 0.3971, 0.3954, 0.3930, 0.3922, 0.3917, 0.3916,\n",
      "        0.3896, 0.3887, 0.3862, 0.3858, 0.3846, 0.3843, 0.3838, 0.3837, 0.3831,\n",
      "        0.3829])}, {'boxes': tensor([[2.5016e+02, 2.5036e+02, 4.7925e+02, 5.0752e+02],\n",
      "        [2.6475e+02, 1.1908e+02, 5.1419e+02, 5.5717e+02],\n",
      "        [1.9982e+02, 2.8705e+02, 5.8406e+02, 5.5386e+02],\n",
      "        [3.3683e+02, 2.4856e+02, 5.4908e+02, 5.4048e+02],\n",
      "        [2.8171e+02, 1.8240e+02, 5.6709e+02, 4.3655e+02],\n",
      "        [5.0930e+02, 3.8214e+02, 6.6972e+02, 5.2837e+02],\n",
      "        [4.1995e+02, 2.6530e+02, 6.1537e+02, 3.9853e+02],\n",
      "        [2.7239e+02, 2.6775e+02, 3.8057e+02, 3.1935e+02],\n",
      "        [4.4428e+02, 6.5570e+02, 5.2087e+02, 7.1927e+02],\n",
      "        [2.8796e+01, 2.5194e+01, 5.9878e+02, 6.9565e+02],\n",
      "        [2.6296e+02, 2.5164e+02, 3.8440e+02, 3.6947e+02],\n",
      "        [2.6718e+02, 2.6040e+02, 3.2732e+02, 3.2194e+02],\n",
      "        [2.7240e+02, 2.5334e+02, 3.7803e+02, 5.1334e+02],\n",
      "        [3.3383e+02, 1.8735e+02, 4.1401e+02, 2.5988e+02],\n",
      "        [4.6818e+02, 3.3618e+02, 6.2506e+02, 5.0900e+02],\n",
      "        [2.5776e+02, 2.5596e+02, 4.8039e+02, 3.3976e+02],\n",
      "        [3.1373e+02, 2.5952e+02, 4.4657e+02, 3.0109e+02],\n",
      "        [3.8962e+02, 5.1414e+02, 5.3770e+02, 6.5017e+02],\n",
      "        [4.3854e+02, 2.4543e+02, 5.0176e+02, 3.2625e+02],\n",
      "        [3.8809e+02, 2.6355e+02, 4.8629e+02, 3.2627e+02],\n",
      "        [2.5094e+02, 3.0763e+02, 2.7137e+02, 3.5038e+02],\n",
      "        [2.8216e+02, 7.1594e+01, 3.8555e+02, 2.6518e+02],\n",
      "        [4.7339e-02, 7.9515e+02, 5.2074e+00, 8.0000e+02],\n",
      "        [2.9129e+02, 2.6419e+02, 5.3027e+02, 3.8769e+02],\n",
      "        [5.5614e-02, 7.9227e+02, 5.1034e+00, 7.9832e+02],\n",
      "        [3.8196e+02, 2.3398e+02, 5.0662e+02, 3.4947e+02],\n",
      "        [1.2971e-01, 7.9529e+02, 1.5955e+01, 7.9982e+02],\n",
      "        [3.8801e+02, 2.3783e+02, 6.2307e+02, 3.5035e+02],\n",
      "        [1.3020e+00, 7.9336e+02, 1.4295e+01, 7.9854e+02],\n",
      "        [1.6637e+02, 2.5153e+02, 4.1633e+02, 5.3465e+02],\n",
      "        [3.2919e+02, 2.3340e+02, 4.5657e+02, 2.8085e+02],\n",
      "        [4.4074e+02, 2.9080e+02, 5.0554e+02, 3.6250e+02],\n",
      "        [4.9979e+02, 3.3071e+02, 5.5825e+02, 3.9191e+02],\n",
      "        [1.9298e-01, 4.9665e+01, 8.2655e+00, 6.8505e+02],\n",
      "        [3.7689e+02, 2.3690e+02, 4.4576e+02, 2.9714e+02],\n",
      "        [4.9099e+02, 4.8107e+02, 6.8593e+02, 5.8624e+02],\n",
      "        [2.4163e+02, 2.0401e+02, 2.9760e+02, 2.6242e+02],\n",
      "        [5.5722e-02, 4.0193e+02, 1.9376e+00, 8.0000e+02],\n",
      "        [4.0910e+02, 2.5757e+02, 5.2634e+02, 4.7237e+02],\n",
      "        [1.9521e+02, 3.4344e+01, 4.4609e+02, 2.5917e+02],\n",
      "        [2.5970e+02, 2.7871e+02, 3.2075e+02, 3.4837e+02],\n",
      "        [3.8238e+02, 1.8611e+02, 6.5713e+02, 4.3689e+02],\n",
      "        [2.6120e+02, 2.3516e+02, 3.4343e+02, 4.6588e+02],\n",
      "        [4.8008e+02, 2.6593e+02, 7.2113e+02, 5.2696e+02],\n",
      "        [2.9870e+02, 1.7100e+02, 4.1816e+02, 2.9268e+02],\n",
      "        [2.7197e+02, 2.6705e+02, 3.3230e+02, 4.0015e+02],\n",
      "        [5.2051e+02, 3.3088e+02, 6.6553e+02, 4.8167e+02],\n",
      "        [3.6564e+02, 2.5400e+02, 4.6906e+02, 3.0709e+02],\n",
      "        [3.5382e+02, 1.8507e+02, 6.0111e+02, 6.8214e+02],\n",
      "        [3.1000e+02, 2.3170e+02, 5.2793e+02, 3.1737e+02],\n",
      "        [4.2525e+02, 2.3215e+02, 5.2290e+02, 3.9339e+02],\n",
      "        [3.3483e-01, 5.5925e+02, 1.2822e+01, 7.9126e+02],\n",
      "        [6.1156e+02, 2.6941e+02, 7.1886e+02, 3.8615e+02],\n",
      "        [2.7970e-01, 3.4416e+02, 1.1271e+01, 7.8809e+02],\n",
      "        [6.2444e+02, 5.0549e+02, 6.7922e+02, 5.6591e+02],\n",
      "        [1.9841e+02, 3.8149e+02, 2.6446e+02, 4.4681e+02],\n",
      "        [7.3289e-02, 1.4837e+02, 2.1248e+00, 5.9770e+02],\n",
      "        [5.3930e+02, 7.1849e+01, 7.1833e+02, 2.1136e+02],\n",
      "        [1.7627e-01, 5.8071e+02, 3.5321e+00, 8.0000e+02],\n",
      "        [4.1715e+02, 2.7458e+02, 4.8902e+02, 3.4331e+02],\n",
      "        [4.4949e+02, 3.8859e+02, 6.0126e+02, 5.3860e+02],\n",
      "        [5.0277e+02, 4.3514e+01, 7.0212e+02, 2.6399e+02],\n",
      "        [2.5334e+02, 3.1107e+02, 2.7534e+02, 3.7136e+02],\n",
      "        [1.6588e+02, 7.6946e+01, 2.9176e+02, 1.9027e+02],\n",
      "        [3.4778e+02, 0.0000e+00, 7.4879e+02, 7.6343e+02],\n",
      "        [4.6420e+02, 4.6227e+02, 5.7354e+02, 5.2736e+02],\n",
      "        [4.6186e+02, 2.4421e+02, 5.4084e+02, 3.2060e+02],\n",
      "        [3.8904e+02, 3.1241e+02, 6.3843e+02, 5.8186e+02],\n",
      "        [4.3841e+02, 4.5165e+02, 6.6509e+02, 5.4134e+02],\n",
      "        [2.6850e+02, 2.1497e+02, 4.5165e+02, 7.0762e+02],\n",
      "        [1.2369e-01, 0.0000e+00, 2.8670e+00, 2.4262e+02],\n",
      "        [1.8586e+02, 7.9797e+02, 5.2519e+02, 8.0000e+02],\n",
      "        [4.9853e+00, 7.9418e+02, 3.1514e+01, 7.9940e+02],\n",
      "        [2.5455e+02, 2.5363e+02, 2.9993e+02, 3.7128e+02],\n",
      "        [4.1014e+02, 2.3763e+02, 4.8068e+02, 3.1348e+02],\n",
      "        [2.5048e+02, 2.1255e+02, 3.0570e+02, 3.4380e+02],\n",
      "        [2.9746e+02, 7.9830e+02, 6.7312e+02, 8.0000e+02],\n",
      "        [3.1267e+02, 4.3418e+01, 4.9030e+02, 3.7485e+02],\n",
      "        [6.3577e+02, 1.7910e+02, 7.1792e+02, 2.6396e+02],\n",
      "        [1.3417e+02, 3.7419e+02, 2.6852e+02, 4.6438e+02],\n",
      "        [1.1458e+01, 7.9465e+02, 6.0231e+01, 7.9978e+02],\n",
      "        [4.5563e+02, 7.1087e+01, 5.5951e+02, 2.6542e+02],\n",
      "        [5.1051e+02, 2.7107e+02, 6.6204e+02, 4.1165e+02],\n",
      "        [2.2222e+02, 7.2461e+01, 4.8516e+02, 1.9494e+02],\n",
      "        [3.8583e+01, 0.0000e+00, 4.9217e+02, 1.0181e+01],\n",
      "        [3.5880e-01, 6.9977e+02, 7.4081e+00, 7.9180e+02],\n",
      "        [4.0092e-01, 7.7726e+02, 8.3895e+00, 7.9449e+02],\n",
      "        [3.7448e+02, 3.5292e+01, 6.4848e+02, 2.6095e+02],\n",
      "        [5.5952e+02, 3.5530e+02, 6.9671e+02, 4.9103e+02],\n",
      "        [2.9493e+02, 1.1227e+02, 4.4948e+02, 2.6603e+02],\n",
      "        [1.1059e+00, 2.2724e+02, 3.1249e+01, 4.9829e+02],\n",
      "        [6.5989e+00, 6.5846e+02, 1.9341e+02, 7.9975e+02],\n",
      "        [6.7761e+02, 2.6591e+02, 7.1482e+02, 3.9191e+02],\n",
      "        [5.2165e+02, 4.9035e+02, 5.8216e+02, 5.5097e+02],\n",
      "        [6.2688e+02, 7.7887e+02, 7.9548e+02, 7.9819e+02],\n",
      "        [5.5923e+02, 1.9555e+02, 6.6755e+02, 2.6102e+02],\n",
      "        [2.6144e+02, 2.8190e+02, 3.1119e+02, 4.0676e+02],\n",
      "        [2.0231e+02, 1.2424e+02, 2.7502e+02, 1.9353e+02],\n",
      "        [4.4847e-01, 6.3969e+02, 5.5036e+00, 8.0000e+02],\n",
      "        [9.9601e-01, 0.0000e+00, 1.2003e+01, 4.5662e+02]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.6480, 0.6337, 0.6197, 0.5835, 0.5689, 0.5533, 0.5516, 0.5460, 0.5336,\n",
      "        0.5250, 0.5176, 0.5161, 0.5078, 0.5051, 0.5038, 0.5007, 0.4985, 0.4910,\n",
      "        0.4888, 0.4887, 0.4863, 0.4800, 0.4795, 0.4778, 0.4777, 0.4747, 0.4733,\n",
      "        0.4722, 0.4695, 0.4693, 0.4671, 0.4655, 0.4629, 0.4623, 0.4604, 0.4584,\n",
      "        0.4573, 0.4554, 0.4545, 0.4539, 0.4531, 0.4519, 0.4510, 0.4488, 0.4466,\n",
      "        0.4440, 0.4361, 0.4361, 0.4349, 0.4339, 0.4339, 0.4330, 0.4326, 0.4325,\n",
      "        0.4294, 0.4254, 0.4217, 0.4197, 0.4177, 0.4168, 0.4165, 0.4165, 0.4143,\n",
      "        0.4132, 0.4128, 0.4116, 0.4086, 0.4063, 0.4061, 0.4059, 0.4052, 0.4045,\n",
      "        0.4044, 0.4025, 0.4004, 0.3995, 0.3968, 0.3949, 0.3947, 0.3923, 0.3916,\n",
      "        0.3901, 0.3892, 0.3887, 0.3880, 0.3878, 0.3874, 0.3866, 0.3866, 0.3854,\n",
      "        0.3850, 0.3840, 0.3834, 0.3833, 0.3832, 0.3827, 0.3826, 0.3812, 0.3812,\n",
      "        0.3808])}]\n",
      "type(pred_boxes[i])=<class 'dict'>\n",
      "type(pred_boxes[i])=<class 'dict'>\n",
      "type(pred_boxes[i])=<class 'dict'>\n",
      "type(pred_boxes[i])=<class 'dict'>\n",
      "IN VALIDATION STEP\n",
      "type(targets)=<class 'tuple'> type(pred_boxes)=<class 'list'>\n",
      "pred_boxes=[{'boxes': tensor([[3.0224e+02, 1.8723e+02, 4.2605e+02, 3.0033e+02],\n",
      "        [1.8973e+02, 0.0000e+00, 6.9400e+02, 7.6139e+02],\n",
      "        [5.4186e+02, 7.6504e+02, 5.6044e+02, 7.7822e+02],\n",
      "        [5.4883e+02, 7.8503e+02, 5.8033e+02, 7.9996e+02],\n",
      "        [4.7187e-02, 7.9506e+02, 5.0926e+00, 8.0000e+02],\n",
      "        [6.2987e-02, 7.9211e+02, 5.1342e+00, 7.9819e+02],\n",
      "        [1.7118e-01, 7.9522e+02, 1.5840e+01, 7.9984e+02],\n",
      "        [5.4131e+02, 7.5967e+02, 5.5641e+02, 7.7423e+02],\n",
      "        [1.4955e-01, 0.0000e+00, 8.7098e+00, 5.9090e+02],\n",
      "        [1.4829e+00, 7.9327e+02, 1.4190e+01, 7.9855e+02],\n",
      "        [4.8898e+02, 7.9796e+02, 7.0143e+02, 8.0000e+02],\n",
      "        [1.4025e+02, 7.4644e+02, 2.0660e+02, 7.9912e+02],\n",
      "        [5.9025e+00, 7.8822e+02, 1.5093e+02, 7.9981e+02],\n",
      "        [4.4498e+02, 7.0156e+02, 5.3270e+02, 7.7090e+02],\n",
      "        [5.1872e+02, 7.6891e+02, 5.8803e+02, 8.0000e+02],\n",
      "        [7.0365e-02, 1.9635e+02, 2.1933e+00, 6.2754e+02],\n",
      "        [3.1475e+02, 6.1932e+02, 4.0219e+02, 7.7094e+02],\n",
      "        [2.3079e+01, 7.8147e+02, 1.6557e+02, 7.9912e+02],\n",
      "        [5.6052e+02, 7.6357e+02, 5.7966e+02, 7.7831e+02],\n",
      "        [2.7298e-01, 2.5734e+02, 8.9063e+00, 8.0000e+02],\n",
      "        [1.0703e+02, 7.2961e+02, 1.7661e+02, 8.0000e+02],\n",
      "        [1.9335e-01, 0.0000e+00, 1.7034e+01, 1.5374e+02],\n",
      "        [5.5298e+02, 7.6393e+02, 5.6940e+02, 7.7952e+02],\n",
      "        [5.1267e-01, 0.0000e+00, 2.1693e+01, 5.5791e+02],\n",
      "        [2.6777e-01, 5.9645e+02, 1.0183e+01, 7.7545e+02],\n",
      "        [2.9166e+02, 2.1396e+02, 3.9255e+02, 5.2569e+02],\n",
      "        [1.1362e+02, 7.8406e+02, 4.5711e+02, 7.9694e+02],\n",
      "        [1.8581e-01, 3.2897e+02, 2.3043e+00, 8.0000e+02],\n",
      "        [1.8789e+00, 7.7031e+02, 6.0090e+01, 7.9995e+02],\n",
      "        [3.7397e+02, 6.8290e+02, 4.1966e+02, 7.7546e+02],\n",
      "        [4.7669e+00, 7.9504e+02, 1.5980e+02, 7.9961e+02],\n",
      "        [3.9738e+02, 6.4321e+02, 5.4012e+02, 7.7994e+02],\n",
      "        [4.3196e-02, 3.9976e+00, 1.7686e+00, 5.0066e+02],\n",
      "        [3.6303e+02, 6.5693e+02, 4.6414e+02, 7.7382e+02],\n",
      "        [5.4315e+02, 7.6748e+02, 5.5575e+02, 7.8170e+02],\n",
      "        [5.0726e+00, 7.9406e+02, 3.0496e+01, 7.9940e+02],\n",
      "        [1.7227e+02, 7.4033e+02, 2.4132e+02, 7.7813e+02],\n",
      "        [1.0785e-01, 0.0000e+00, 2.5947e+00, 3.0006e+02],\n",
      "        [2.8593e+02, 3.0181e+02, 3.6599e+02, 6.0464e+02],\n",
      "        [3.6413e+02, 6.4540e+02, 4.1287e+02, 7.6690e+02],\n",
      "        [3.7647e+02, 5.6597e+02, 4.6959e+02, 7.6473e+02],\n",
      "        [5.5400e+02, 0.0000e+00, 8.0000e+02, 1.1961e+01],\n",
      "        [4.9468e-01, 2.8623e+02, 3.1172e+00, 6.4669e+02],\n",
      "        [5.8764e+00, 7.7021e+02, 2.3118e+02, 7.9982e+02],\n",
      "        [6.7453e+00, 0.0000e+00, 2.4221e+02, 1.2691e+01],\n",
      "        [2.8744e+02, 7.9757e+02, 6.3735e+02, 7.9999e+02],\n",
      "        [5.2115e+02, 7.7355e+02, 8.0000e+02, 7.9994e+02],\n",
      "        [3.8416e+01, 0.0000e+00, 4.3176e+02, 1.0741e+01],\n",
      "        [4.2395e-01, 7.7733e+02, 8.1481e+00, 7.9400e+02],\n",
      "        [1.1259e+00, 0.0000e+00, 3.3331e+01, 1.7668e+02],\n",
      "        [7.4381e+01, 2.8224e+01, 7.6894e+02, 4.8694e+02],\n",
      "        [1.1673e+00, 1.2429e+02, 2.6889e+01, 8.0000e+02],\n",
      "        [1.3573e+00, 0.0000e+00, 4.4354e+01, 7.0365e+01],\n",
      "        [8.2281e+01, 7.5044e+02, 2.1998e+02, 7.9809e+02],\n",
      "        [9.2043e+01, 6.1071e+02, 2.5652e+02, 7.7923e+02],\n",
      "        [9.3803e-01, 3.8144e+02, 2.2729e+01, 7.5915e+02],\n",
      "        [1.3986e+00, 2.2941e+02, 4.6409e+01, 4.9348e+02],\n",
      "        [2.7850e-01, 5.7527e+02, 3.4179e+00, 8.0000e+02],\n",
      "        [5.7184e+02, 7.6635e+02, 5.8354e+02, 7.8175e+02],\n",
      "        [5.2650e-01, 3.9525e+01, 2.5209e+00, 6.0260e+02],\n",
      "        [1.8948e+02, 0.0000e+00, 6.1235e+02, 7.1246e+00],\n",
      "        [6.9988e-01, 4.3042e+02, 1.3606e+01, 8.0000e+02],\n",
      "        [2.8306e-01, 6.9664e+02, 7.4098e+00, 7.9201e+02],\n",
      "        [6.2839e-01, 6.4177e+02, 1.7172e+01, 8.0000e+02],\n",
      "        [7.8749e+02, 7.9520e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [4.2180e+02, 7.3194e+02, 5.1242e+02, 7.7525e+02],\n",
      "        [1.1485e+01, 7.9451e+02, 5.8155e+01, 7.9979e+02],\n",
      "        [2.9088e+01, 7.9763e+02, 3.4276e+02, 7.9999e+02],\n",
      "        [7.1320e+02, 0.0000e+00, 8.0000e+02, 4.7953e+01],\n",
      "        [1.2294e+02, 7.8958e+02, 4.5806e+02, 7.9983e+02],\n",
      "        [3.7412e+02, 7.3250e+02, 4.3227e+02, 7.8118e+02],\n",
      "        [7.7012e+02, 0.0000e+00, 8.0000e+02, 2.1415e+02],\n",
      "        [2.3420e+00, 0.0000e+00, 4.7366e+01, 7.4874e+02],\n",
      "        [7.7505e+02, 7.8908e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [3.3421e+02, 7.3722e+02, 3.9149e+02, 8.0000e+02],\n",
      "        [5.9274e+02, 0.0000e+00, 8.0000e+02, 8.0000e+02],\n",
      "        [3.3426e+02, 0.0000e+00, 7.9980e+02, 9.8539e+00],\n",
      "        [7.3951e+02, 0.0000e+00, 8.0000e+02, 1.7162e+02],\n",
      "        [7.7343e+02, 5.2507e+02, 8.0000e+02, 7.9917e+02],\n",
      "        [7.5042e+00, 0.0000e+00, 2.1428e+02, 7.8849e+02],\n",
      "        [3.8368e+02, 7.8062e+02, 7.1571e+02, 7.9869e+02],\n",
      "        [7.7498e+02, 0.0000e+00, 8.0000e+02, 8.0000e+02],\n",
      "        [7.8032e+02, 6.3429e+02, 7.9955e+02, 7.8157e+02],\n",
      "        [6.5029e+02, 7.7949e+02, 7.8133e+02, 7.9917e+02],\n",
      "        [3.3409e+02, 6.5104e+02, 5.9525e+02, 7.6395e+02],\n",
      "        [4.5930e-01, 7.6199e+02, 8.3542e+00, 7.9258e+02],\n",
      "        [2.0884e+01, 7.5234e+02, 1.2355e+02, 7.9919e+02],\n",
      "        [3.3732e+02, 5.6405e+02, 4.3593e+02, 7.7021e+02],\n",
      "        [2.5694e+02, 2.7171e+02, 3.3449e+02, 6.0870e+02],\n",
      "        [1.5316e+01, 0.0000e+00, 3.2536e+02, 2.7930e+01],\n",
      "        [1.0786e+01, 6.6343e+02, 1.8208e+02, 7.9831e+02],\n",
      "        [2.9289e-01, 7.6543e+02, 4.8150e+00, 7.8672e+02],\n",
      "        [2.7233e+02, 2.0776e+02, 3.5278e+02, 5.6435e+02],\n",
      "        [7.7041e+02, 6.6680e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [1.8842e+02, 7.2518e+02, 2.5479e+02, 8.0000e+02],\n",
      "        [6.9088e+02, 7.6897e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [4.4689e+02, 7.1174e+02, 5.1083e+02, 8.0000e+02],\n",
      "        [5.1357e+02, 7.9518e+02, 6.1094e+02, 7.9880e+02],\n",
      "        [7.9031e+02, 9.0230e+01, 7.9997e+02, 7.0998e+02],\n",
      "        [4.3967e+02, 0.0000e+00, 8.0000e+02, 2.5639e+01]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.5132, 0.5058, 0.5027, 0.4660, 0.4653, 0.4652, 0.4622, 0.4579, 0.4568,\n",
      "        0.4553, 0.4487, 0.4477, 0.4464, 0.4450, 0.4415, 0.4368, 0.4361, 0.4345,\n",
      "        0.4325, 0.4300, 0.4299, 0.4275, 0.4249, 0.4204, 0.4151, 0.4150, 0.4138,\n",
      "        0.4132, 0.4128, 0.4127, 0.4106, 0.4106, 0.4076, 0.4051, 0.4033, 0.4014,\n",
      "        0.4008, 0.4002, 0.3972, 0.3972, 0.3958, 0.3953, 0.3943, 0.3937, 0.3932,\n",
      "        0.3920, 0.3917, 0.3908, 0.3830, 0.3805, 0.3805, 0.3794, 0.3788, 0.3783,\n",
      "        0.3772, 0.3766, 0.3763, 0.3763, 0.3750, 0.3747, 0.3744, 0.3733, 0.3730,\n",
      "        0.3730, 0.3727, 0.3709, 0.3697, 0.3693, 0.3684, 0.3670, 0.3667, 0.3659,\n",
      "        0.3655, 0.3649, 0.3646, 0.3618, 0.3612, 0.3605, 0.3599, 0.3594, 0.3584,\n",
      "        0.3571, 0.3567, 0.3549, 0.3546, 0.3540, 0.3538, 0.3528, 0.3526, 0.3519,\n",
      "        0.3518, 0.3480, 0.3468, 0.3449, 0.3448, 0.3443, 0.3439, 0.3422, 0.3420,\n",
      "        0.3418])}, {'boxes': tensor([[3.8873e+01, 0.0000e+00, 5.9563e+02, 7.3225e+02],\n",
      "        [1.3409e+02, 5.0665e+02, 1.8764e+02, 5.6951e+02],\n",
      "        [2.3561e+02, 0.0000e+00, 7.3180e+02, 7.9264e+02],\n",
      "        [1.3450e+02, 5.1213e+02, 2.2060e+02, 6.4614e+02],\n",
      "        [2.5264e+02, 4.2909e+02, 3.9586e+02, 5.6417e+02],\n",
      "        [3.8006e+02, 3.0429e+02, 5.0206e+02, 4.2743e+02],\n",
      "        [1.2507e+02, 4.9762e+02, 1.9037e+02, 6.2615e+02],\n",
      "        [2.7568e-02, 7.9507e+02, 5.1630e+00, 8.0000e+02],\n",
      "        [3.7541e-02, 7.9226e+02, 5.1424e+00, 7.9830e+02],\n",
      "        [9.6772e-02, 7.9520e+02, 1.5630e+01, 7.9981e+02],\n",
      "        [5.4661e+02, 3.8441e+02, 6.1072e+02, 4.9741e+02],\n",
      "        [5.1879e+02, 3.4598e+02, 6.1578e+02, 5.3486e+02],\n",
      "        [1.1903e+02, 7.4757e+02, 1.9291e+02, 7.9863e+02],\n",
      "        [1.5765e+00, 7.9335e+02, 1.3955e+01, 7.9860e+02],\n",
      "        [2.1415e-01, 0.0000e+00, 9.3466e+00, 5.8608e+02],\n",
      "        [1.2850e+02, 4.4385e+02, 2.2439e+02, 6.0874e+02],\n",
      "        [2.9368e-01, 2.3507e+02, 9.0670e+00, 8.0000e+02],\n",
      "        [5.0841e-02, 5.3161e+01, 2.1731e+00, 5.4625e+02],\n",
      "        [4.9953e-01, 0.0000e+00, 2.2261e+01, 5.5103e+02],\n",
      "        [6.9840e-02, 3.2045e+02, 2.1026e+00, 7.5562e+02],\n",
      "        [2.3868e-01, 0.0000e+00, 1.6867e+01, 1.5134e+02],\n",
      "        [1.1547e+00, 0.0000e+00, 5.4110e+01, 3.8497e+01],\n",
      "        [5.3927e+00, 7.8861e+02, 1.5111e+02, 7.9982e+02],\n",
      "        [2.3630e+01, 7.8152e+02, 1.6571e+02, 7.9896e+02],\n",
      "        [2.0636e-01, 5.9805e+02, 1.0045e+01, 7.7967e+02],\n",
      "        [1.6222e+02, 5.0301e+02, 3.0635e+02, 6.4198e+02],\n",
      "        [1.3052e-01, 0.0000e+00, 2.5916e+00, 2.9551e+02],\n",
      "        [7.0486e-02, 5.0319e+02, 2.3552e+00, 8.0000e+02],\n",
      "        [1.8408e+01, 0.0000e+00, 3.7098e+02, 1.0998e+01],\n",
      "        [3.9040e+02, 3.2392e+02, 4.8447e+02, 6.8517e+02],\n",
      "        [4.9059e+00, 7.9408e+02, 2.9527e+01, 7.9938e+02],\n",
      "        [1.1129e+02, 4.6862e+02, 2.0167e+02, 6.5903e+02],\n",
      "        [4.5523e-01, 2.9822e+02, 2.9517e+00, 6.9054e+02],\n",
      "        [2.9567e+02, 7.9819e+02, 6.6362e+02, 8.0000e+02],\n",
      "        [3.5391e-01, 7.7888e+02, 8.0870e+00, 7.9455e+02],\n",
      "        [7.5292e-01, 4.8412e+02, 3.4404e+00, 8.0000e+02],\n",
      "        [5.7660e+02, 0.0000e+00, 8.0000e+02, 1.2991e+01],\n",
      "        [7.1571e+01, 4.8670e+01, 7.5635e+02, 4.5629e+02],\n",
      "        [1.4045e+00, 2.3215e+02, 3.8527e+01, 5.0395e+02],\n",
      "        [8.6004e-01, 1.6285e+02, 2.4525e+01, 8.0000e+02],\n",
      "        [2.0054e+02, 0.0000e+00, 6.3295e+02, 7.3942e+00],\n",
      "        [2.8518e+02, 4.3726e+02, 3.7347e+02, 7.3519e+02],\n",
      "        [1.1116e+00, 0.0000e+00, 3.4406e+01, 1.7072e+02],\n",
      "        [3.2282e-01, 6.3273e+02, 5.2394e+00, 8.0000e+02],\n",
      "        [7.8865e+02, 7.9504e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [2.8435e-01, 7.0026e+02, 7.2823e+00, 7.9090e+02],\n",
      "        [1.4214e+02, 5.1213e+02, 3.1654e+02, 7.4700e+02],\n",
      "        [4.8394e+02, 7.9787e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [1.3991e+00, 0.0000e+00, 4.5318e+01, 7.3705e+01],\n",
      "        [4.2386e+02, 0.0000e+00, 8.0000e+02, 8.8313e+00],\n",
      "        [3.6404e+02, 3.0166e+02, 4.5258e+02, 6.8409e+02],\n",
      "        [5.5312e+00, 7.9500e+02, 1.5573e+02, 7.9963e+02],\n",
      "        [4.9296e+02, 4.6329e+02, 5.7761e+02, 7.2830e+02],\n",
      "        [6.0742e-01, 6.3781e+02, 1.6802e+01, 8.0000e+02],\n",
      "        [4.3916e+02, 3.3388e+02, 5.3267e+02, 6.6192e+02],\n",
      "        [7.9078e+02, 7.9279e+02, 8.0000e+02, 7.9917e+02],\n",
      "        [7.1129e+02, 0.0000e+00, 8.0000e+02, 4.6475e+01],\n",
      "        [7.7997e+02, 7.8929e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [6.6712e+02, 8.6176e-01, 8.0000e+02, 8.0000e+02],\n",
      "        [7.7823e+02, 7.9415e+02, 7.9883e+02, 7.9943e+02],\n",
      "        [8.9249e+01, 4.9261e+02, 2.4428e+02, 7.7332e+02],\n",
      "        [1.1624e+02, 4.8644e+02, 2.8678e+02, 5.8401e+02],\n",
      "        [7.8808e+02, 0.0000e+00, 8.0000e+02, 6.1082e+01],\n",
      "        [1.1409e+01, 7.9458e+02, 5.6829e+01, 7.9980e+02],\n",
      "        [7.3926e+02, 0.0000e+00, 8.0000e+02, 1.6140e+02],\n",
      "        [1.5818e+01, 2.4520e+00, 3.0122e+02, 1.6140e+01],\n",
      "        [7.7013e+02, 0.0000e+00, 8.0000e+02, 2.2005e+02],\n",
      "        [8.4761e-01, 4.3092e+02, 1.4001e+01, 8.0000e+02],\n",
      "        [7.8190e+02, 5.6848e+02, 7.9914e+02, 7.8749e+02],\n",
      "        [7.6676e+02, 2.5500e+01, 8.0000e+02, 8.0000e+02],\n",
      "        [5.3228e+02, 3.6485e+02, 6.2739e+02, 6.5175e+02],\n",
      "        [1.2793e+02, 9.9872e+01, 3.1248e+02, 6.4007e+02],\n",
      "        [1.6201e+02, 2.3447e+02, 7.2516e+02, 6.3944e+02],\n",
      "        [2.7459e+02, 2.8707e+02, 5.2168e+02, 6.1300e+02],\n",
      "        [4.8635e-01, 7.6418e+02, 8.3205e+00, 7.9293e+02],\n",
      "        [4.9997e+02, 3.4486e+02, 5.9822e+02, 6.3743e+02],\n",
      "        [1.0987e+02, 4.3762e+02, 3.3736e+02, 6.9348e+02],\n",
      "        [1.2328e+02, 5.4967e-01, 4.9986e+02, 1.2725e+01],\n",
      "        [2.8761e-01, 7.6758e+02, 4.8761e+00, 7.8766e+02],\n",
      "        [7.6958e+02, 6.6163e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [4.5950e+02, 6.1193e+02, 6.2249e+02, 7.7903e+02],\n",
      "        [3.9882e+02, 0.0000e+00, 8.0000e+02, 2.5251e+01],\n",
      "        [1.2000e+00, 6.2147e+02, 3.1003e+01, 8.0000e+02],\n",
      "        [5.6105e+02, 7.6998e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [3.3139e+02, 3.8025e+02, 5.1591e+02, 7.5728e+02],\n",
      "        [7.9096e+02, 2.5260e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [3.0926e+02, 5.1190e+02, 4.0665e+02, 7.6062e+02],\n",
      "        [4.1150e+01, 6.7017e+02, 1.9447e+02, 7.9563e+02],\n",
      "        [4.8709e+02, 1.4665e+02, 5.8531e+02, 3.7501e+02],\n",
      "        [4.0178e+00, 7.4129e+02, 8.0558e+01, 8.0000e+02],\n",
      "        [6.0275e+00, 6.4366e+02, 6.6390e+01, 7.1029e+02],\n",
      "        [7.0480e+02, 7.7036e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [6.2968e+02, 5.6243e+02, 7.3045e+02, 7.8186e+02],\n",
      "        [8.4155e+01, 6.7889e+01, 2.5101e+02, 7.0633e+02],\n",
      "        [4.7676e+02, 5.5220e+02, 7.1779e+02, 7.8207e+02],\n",
      "        [4.9556e+02, 2.7827e+00, 8.0000e+02, 1.8226e+01],\n",
      "        [7.6523e+02, 7.9535e+02, 7.9474e+02, 7.9991e+02],\n",
      "        [5.4648e+00, 7.6688e+02, 3.6039e+01, 7.9813e+02],\n",
      "        [3.4248e+00, 0.0000e+00, 7.7140e+01, 2.6349e+02],\n",
      "        [6.3055e+02, 7.7871e+02, 7.9001e+02, 7.9880e+02]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.5795, 0.5473, 0.5382, 0.5364, 0.5163, 0.5057, 0.5043, 0.4765, 0.4760,\n",
      "        0.4714, 0.4678, 0.4659, 0.4652, 0.4584, 0.4544, 0.4476, 0.4311, 0.4305,\n",
      "        0.4282, 0.4258, 0.4228, 0.4185, 0.4174, 0.4130, 0.4126, 0.4101, 0.4096,\n",
      "        0.4090, 0.4063, 0.4037, 0.4036, 0.4034, 0.4023, 0.4022, 0.3952, 0.3930,\n",
      "        0.3918, 0.3887, 0.3868, 0.3854, 0.3854, 0.3843, 0.3807, 0.3803, 0.3802,\n",
      "        0.3796, 0.3787, 0.3787, 0.3778, 0.3763, 0.3760, 0.3749, 0.3740, 0.3740,\n",
      "        0.3735, 0.3712, 0.3685, 0.3683, 0.3674, 0.3671, 0.3670, 0.3670, 0.3662,\n",
      "        0.3648, 0.3639, 0.3625, 0.3595, 0.3580, 0.3568, 0.3565, 0.3564, 0.3560,\n",
      "        0.3551, 0.3542, 0.3539, 0.3528, 0.3514, 0.3507, 0.3495, 0.3484, 0.3482,\n",
      "        0.3461, 0.3455, 0.3445, 0.3443, 0.3442, 0.3442, 0.3436, 0.3436, 0.3419,\n",
      "        0.3406, 0.3392, 0.3389, 0.3386, 0.3380, 0.3364, 0.3354, 0.3341, 0.3339,\n",
      "        0.3313])}, {'boxes': tensor([[3.2971e+02, 4.6814e+02, 3.5455e+02, 4.9176e+02],\n",
      "        [1.6400e+02, 0.0000e+00, 7.0883e+02, 7.8834e+02],\n",
      "        [4.0623e-02, 7.9496e+02, 5.2007e+00, 8.0000e+02],\n",
      "        [5.3907e-02, 7.9206e+02, 5.1557e+00, 7.9819e+02],\n",
      "        [3.7625e+02, 3.9941e+02, 4.7485e+02, 6.3189e+02],\n",
      "        [2.1104e+02, 5.5363e+02, 2.5310e+02, 6.7903e+02],\n",
      "        [1.3976e-01, 7.9509e+02, 1.5644e+01, 7.9977e+02],\n",
      "        [1.3027e-01, 0.0000e+00, 9.9122e+00, 4.8335e+02],\n",
      "        [1.6621e+00, 7.9318e+02, 1.3935e+01, 7.9856e+02],\n",
      "        [2.1756e-01, 5.7678e+01, 7.8586e+00, 7.2414e+02],\n",
      "        [8.8986e-02, 2.7200e+02, 2.1638e+00, 7.2380e+02],\n",
      "        [4.2159e-01, 5.9187e+02, 1.0127e+01, 7.7677e+02],\n",
      "        [4.5430e-01, 4.1563e+02, 1.2497e+01, 8.0000e+02],\n",
      "        [2.3969e-01, 4.8026e+02, 3.1551e+00, 7.7913e+02],\n",
      "        [3.1128e+00, 7.9434e+02, 1.1063e+01, 8.0000e+02],\n",
      "        [5.7621e-01, 0.0000e+00, 2.3721e+01, 8.0000e+02],\n",
      "        [2.5065e+01, 7.8068e+02, 1.6632e+02, 7.9901e+02],\n",
      "        [3.8772e+02, 7.9854e+02, 7.8675e+02, 8.0000e+02],\n",
      "        [4.7598e-02, 1.1697e+02, 2.0732e+00, 5.8084e+02],\n",
      "        [4.3931e+01, 0.0000e+00, 4.3611e+02, 1.0566e+01],\n",
      "        [1.4813e+01, 0.0000e+00, 2.3438e+02, 7.8364e+02],\n",
      "        [4.4072e+02, 2.7160e+02, 5.7395e+02, 3.2481e+02],\n",
      "        [5.4269e+00, 7.9390e+02, 2.9684e+01, 7.9939e+02],\n",
      "        [7.9749e-02, 0.0000e+00, 2.8797e+00, 2.2621e+02],\n",
      "        [9.1220e+01, 5.3293e+01, 2.5781e+02, 6.6511e+02],\n",
      "        [0.0000e+00, 7.9805e+02, 3.3364e+02, 8.0000e+02],\n",
      "        [9.1920e-01, 3.9530e+02, 2.3507e+01, 7.6413e+02],\n",
      "        [3.8609e-01, 7.7806e+02, 8.2250e+00, 7.9424e+02],\n",
      "        [7.0619e+00, 0.0000e+00, 2.4372e+02, 1.2788e+01],\n",
      "        [1.4672e+00, 2.2298e+02, 3.6458e+01, 8.0000e+02],\n",
      "        [3.7377e+02, 4.5534e+02, 4.6722e+02, 7.4289e+02],\n",
      "        [5.6336e+02, 0.0000e+00, 8.0000e+02, 1.2012e+01],\n",
      "        [9.1680e+00, 7.8774e+02, 1.8936e+02, 7.9992e+02],\n",
      "        [1.2788e+02, 0.0000e+00, 5.9638e+02, 8.3423e+00],\n",
      "        [7.6961e+02, 3.7396e+02, 8.0000e+02, 7.8861e+02],\n",
      "        [2.3180e-01, 6.5139e+02, 4.5360e+00, 7.9356e+02],\n",
      "        [5.2141e+02, 3.2618e+02, 5.8873e+02, 4.4869e+02],\n",
      "        [1.3926e+00, 0.0000e+00, 4.4852e+01, 7.1674e+01],\n",
      "        [3.0592e-01, 6.9660e+02, 7.4621e+00, 7.9164e+02],\n",
      "        [4.1760e+02, 2.7051e+02, 5.9162e+02, 4.0937e+02],\n",
      "        [7.8893e+02, 7.9506e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [3.1262e+02, 4.3350e+02, 3.9904e+02, 7.1435e+02],\n",
      "        [1.2222e+00, 0.0000e+00, 3.3639e+01, 1.7952e+02],\n",
      "        [7.9092e+02, 7.9282e+02, 8.0000e+02, 7.9912e+02],\n",
      "        [3.3824e+02, 5.9962e+02, 4.8710e+02, 7.6519e+02],\n",
      "        [2.8835e+02, 0.0000e+00, 6.9209e+02, 6.1077e+00],\n",
      "        [2.7531e+02, 7.9793e+02, 6.9357e+02, 8.0000e+02],\n",
      "        [7.8024e+02, 7.8927e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [7.7876e+02, 7.9427e+02, 7.9892e+02, 7.9940e+02],\n",
      "        [8.0312e+01, 5.8871e+02, 1.9286e+02, 7.7437e+02],\n",
      "        [9.5068e+01, 3.6565e+01, 8.0000e+02, 4.7865e+02],\n",
      "        [7.3909e+02, 0.0000e+00, 8.0000e+02, 1.6047e+02],\n",
      "        [5.1736e+00, 7.9503e+02, 1.5828e+02, 7.9975e+02],\n",
      "        [1.5463e+00, 6.1750e+02, 3.1320e+01, 8.0000e+02],\n",
      "        [5.8158e+02, 3.1243e+02, 6.2582e+02, 4.3331e+02],\n",
      "        [7.7568e+02, 0.0000e+00, 8.0000e+02, 8.0000e+02],\n",
      "        [5.4413e-01, 0.0000e+00, 2.6489e+00, 3.7860e+02],\n",
      "        [7.7002e+02, 0.0000e+00, 8.0000e+02, 2.0758e+02],\n",
      "        [4.1907e+02, 0.0000e+00, 8.0000e+02, 8.4226e+00],\n",
      "        [1.5397e+00, 2.3320e+02, 4.4434e+01, 5.0114e+02],\n",
      "        [1.3377e+01, 0.0000e+00, 3.2026e+02, 2.7921e+01],\n",
      "        [4.7663e-01, 7.6279e+02, 8.4871e+00, 7.9275e+02],\n",
      "        [1.2473e+01, 7.9436e+02, 5.6956e+01, 7.9979e+02],\n",
      "        [3.5899e+02, 2.8881e+02, 6.0669e+02, 5.9946e+02],\n",
      "        [5.1617e+01, 2.0014e+00, 3.9262e+02, 1.7001e+01],\n",
      "        [7.1249e+02, 0.0000e+00, 8.0000e+02, 4.9149e+01],\n",
      "        [6.2369e+02, 7.7890e+02, 7.9346e+02, 7.9885e+02],\n",
      "        [2.9433e-01, 7.6662e+02, 4.8098e+00, 7.8724e+02],\n",
      "        [6.2630e+00, 6.0807e+02, 1.9085e+02, 7.9943e+02],\n",
      "        [3.3912e+02, 6.3995e+02, 4.4513e+02, 8.0000e+02],\n",
      "        [7.6618e+02, 7.9535e+02, 7.9547e+02, 7.9986e+02],\n",
      "        [4.6486e+02, 3.8312e+02, 5.9807e+02, 5.4288e+02],\n",
      "        [3.8785e+02, 2.8166e+02, 5.5523e+02, 4.5516e+02],\n",
      "        [3.9766e+02, 2.9837e+02, 5.0850e+02, 5.7966e+02],\n",
      "        [4.9303e+02, 2.5353e+02, 5.9867e+02, 4.1733e+02],\n",
      "        [5.1042e+02, 7.8415e+02, 8.0000e+02, 7.9969e+02],\n",
      "        [3.4772e+02, 4.2603e+02, 4.3165e+02, 7.3296e+02],\n",
      "        [9.9093e+01, 7.8968e+02, 4.6263e+02, 7.9982e+02],\n",
      "        [4.4507e+02, 1.3700e+02, 5.8630e+02, 2.9071e+02],\n",
      "        [1.5674e+01, 7.5444e+02, 8.3430e+01, 8.0000e+02],\n",
      "        [7.0894e+02, 0.0000e+00, 8.0000e+02, 8.0000e+02],\n",
      "        [6.9781e+02, 7.6982e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [7.8360e+02, 4.9323e+02, 7.9896e+02, 8.0000e+02],\n",
      "        [2.3764e+00, 0.0000e+00, 1.4175e+01, 3.9008e+02],\n",
      "        [8.6813e+01, 7.7592e+02, 5.7482e+02, 7.9996e+02],\n",
      "        [7.8940e+02, 2.8219e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [2.5071e+00, 0.0000e+00, 4.9142e+01, 7.3067e+02],\n",
      "        [1.4005e+02, 1.5841e+02, 3.4137e+02, 6.9826e+02],\n",
      "        [4.5208e+02, 3.3868e+02, 5.5655e+02, 6.3237e+02],\n",
      "        [4.1011e+02, 0.0000e+00, 8.0000e+02, 2.4321e+01],\n",
      "        [7.8953e+02, 0.0000e+00, 7.9977e+02, 5.4688e+02],\n",
      "        [1.6998e+02, 1.4942e+00, 6.2283e+02, 1.3444e+01],\n",
      "        [7.7929e+02, 6.4881e+02, 7.9950e+02, 7.8485e+02],\n",
      "        [5.3607e+00, 7.6662e+02, 3.6144e+01, 7.9835e+02],\n",
      "        [7.4162e+02, 6.6243e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [1.0237e+01, 7.7189e+02, 2.9455e+02, 7.9980e+02],\n",
      "        [5.3579e+02, 3.7029e+02, 7.1857e+02, 7.7126e+02],\n",
      "        [3.3683e+00, 0.0000e+00, 7.1727e+01, 2.4819e+02],\n",
      "        [5.2031e+02, 1.8851e+02, 5.8886e+02, 2.9764e+02],\n",
      "        [5.8316e+02, 3.3358e+02, 6.8506e+02, 6.3858e+02]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.5386, 0.5091, 0.4777, 0.4736, 0.4708, 0.4678, 0.4667, 0.4646, 0.4594,\n",
      "        0.4545, 0.4538, 0.4298, 0.4261, 0.4247, 0.4197, 0.4191, 0.4127, 0.4117,\n",
      "        0.4079, 0.4066, 0.4058, 0.4020, 0.3992, 0.3966, 0.3954, 0.3940, 0.3912,\n",
      "        0.3904, 0.3870, 0.3861, 0.3851, 0.3850, 0.3849, 0.3845, 0.3831, 0.3820,\n",
      "        0.3806, 0.3802, 0.3798, 0.3792, 0.3786, 0.3784, 0.3770, 0.3737, 0.3726,\n",
      "        0.3714, 0.3689, 0.3687, 0.3682, 0.3669, 0.3654, 0.3652, 0.3652, 0.3633,\n",
      "        0.3621, 0.3616, 0.3603, 0.3601, 0.3544, 0.3543, 0.3537, 0.3528, 0.3506,\n",
      "        0.3495, 0.3495, 0.3495, 0.3488, 0.3486, 0.3468, 0.3465, 0.3443, 0.3414,\n",
      "        0.3410, 0.3406, 0.3401, 0.3400, 0.3392, 0.3385, 0.3381, 0.3377, 0.3368,\n",
      "        0.3367, 0.3353, 0.3348, 0.3341, 0.3333, 0.3331, 0.3324, 0.3311, 0.3301,\n",
      "        0.3296, 0.3288, 0.3287, 0.3281, 0.3281, 0.3278, 0.3265, 0.3263, 0.3261,\n",
      "        0.3260])}, {'boxes': tensor([[7.8061e-01, 0.0000e+00, 7.6348e+02, 7.4928e+02],\n",
      "        [1.9294e+02, 3.5962e+02, 2.3899e+02, 4.2914e+02],\n",
      "        [2.2280e+02, 5.3994e+02, 2.8690e+02, 6.1026e+02],\n",
      "        [9.3753e-02, 2.4250e+02, 2.1420e+00, 7.0548e+02],\n",
      "        [3.7467e-02, 7.9499e+02, 5.4567e+00, 8.0000e+02],\n",
      "        [3.3816e+02, 5.2338e+02, 3.9532e+02, 5.7976e+02],\n",
      "        [1.6899e-01, 4.8913e+01, 8.0579e+00, 7.2383e+02],\n",
      "        [5.3025e-02, 7.9218e+02, 5.4639e+00, 7.9822e+02],\n",
      "        [5.0711e+02, 5.2188e+02, 5.2751e+02, 5.4827e+02],\n",
      "        [1.5076e-01, 7.9511e+02, 1.5787e+01, 7.9975e+02],\n",
      "        [1.6019e-01, 0.0000e+00, 1.0557e+01, 3.5181e+02],\n",
      "        [3.1005e-01, 5.9832e+02, 1.0268e+01, 7.8040e+02],\n",
      "        [6.7624e-02, 4.8893e+02, 2.4842e+00, 8.0000e+02],\n",
      "        [1.6552e+00, 7.9340e+02, 1.4049e+01, 7.9867e+02],\n",
      "        [2.3848e+02, 5.4693e+02, 2.9155e+02, 6.4147e+02],\n",
      "        [2.6702e+02, 7.0941e+02, 3.4670e+02, 7.7099e+02],\n",
      "        [2.8319e-01, 3.1276e+02, 9.9737e+00, 8.0000e+02],\n",
      "        [1.7795e+02, 2.6405e+02, 6.9007e+02, 8.0000e+02],\n",
      "        [5.4567e-01, 0.0000e+00, 2.2003e+01, 5.6001e+02],\n",
      "        [8.1013e-01, 2.3616e+02, 3.0539e+01, 5.0644e+02],\n",
      "        [1.8369e-01, 0.0000e+00, 1.8895e+00, 5.7330e+02],\n",
      "        [2.3181e-01, 5.6182e+02, 3.9292e+00, 8.0000e+02],\n",
      "        [1.7978e-01, 0.0000e+00, 2.5972e+00, 2.9623e+02],\n",
      "        [2.1124e+02, 5.2150e+02, 4.0384e+02, 6.2420e+02],\n",
      "        [1.1548e+02, 0.0000e+00, 5.4674e+02, 9.3698e+00],\n",
      "        [4.6956e+00, 0.0000e+00, 2.0858e+02, 1.3593e+01],\n",
      "        [3.4039e+01, 0.0000e+00, 3.8497e+02, 1.1258e+01],\n",
      "        [6.1542e+01, 1.5338e+02, 3.8108e+02, 8.0000e+02],\n",
      "        [7.8946e+02, 7.9506e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [1.5966e+02, 3.1850e+02, 2.4230e+02, 5.1865e+02],\n",
      "        [4.5903e+02, 0.0000e+00, 8.0000e+02, 9.4657e+00],\n",
      "        [3.5678e-01, 7.7941e+02, 7.9888e+00, 7.9469e+02],\n",
      "        [3.5422e+02, 3.2987e+02, 5.6695e+02, 6.8112e+02],\n",
      "        [7.8017e+02, 7.9396e+02, 7.9979e+02, 7.9920e+02],\n",
      "        [1.1274e+00, 0.0000e+00, 3.3297e+01, 1.7186e+02],\n",
      "        [4.6300e+00, 7.9403e+02, 2.9772e+01, 7.9945e+02],\n",
      "        [8.3807e+00, 7.9789e+02, 3.3188e+02, 8.0000e+02],\n",
      "        [7.9147e+02, 7.9267e+02, 8.0000e+02, 7.9914e+02],\n",
      "        [1.9594e+02, 3.7289e+02, 2.9312e+02, 6.3024e+02],\n",
      "        [6.7427e-01, 4.7574e+02, 1.4810e+01, 8.0000e+02],\n",
      "        [8.2410e+01, 5.5698e+01, 8.0000e+02, 4.8468e+02],\n",
      "        [3.1107e+00, 6.5716e+02, 2.0199e+02, 7.9938e+02],\n",
      "        [2.3530e+01, 7.8043e+02, 1.6421e+02, 7.9910e+02],\n",
      "        [2.5755e+02, 4.9922e+02, 3.5449e+02, 7.6616e+02],\n",
      "        [3.2152e+02, 4.7764e+02, 4.1964e+02, 7.6124e+02],\n",
      "        [1.9681e+02, 7.0680e+02, 3.2315e+02, 7.6991e+02],\n",
      "        [2.9194e+02, 5.2117e+02, 3.9423e+02, 7.6567e+02],\n",
      "        [1.7434e+00, 0.0000e+00, 5.2076e+01, 7.2437e+01],\n",
      "        [7.3771e+02, 0.0000e+00, 8.0000e+02, 1.5452e+02],\n",
      "        [3.1865e+02, 5.7730e+02, 4.5614e+02, 7.5133e+02],\n",
      "        [1.7200e+02, 3.2632e+02, 2.5481e+02, 6.4434e+02],\n",
      "        [7.6961e+02, 4.5771e+01, 8.0000e+02, 8.0000e+02],\n",
      "        [1.0045e+00, 4.1823e+02, 2.3694e+01, 7.7506e+02],\n",
      "        [7.0808e+02, 0.0000e+00, 8.0000e+02, 4.7767e+01],\n",
      "        [3.4850e+02, 7.9805e+02, 7.8555e+02, 8.0000e+02],\n",
      "        [2.5912e+02, 0.0000e+00, 6.6795e+02, 7.6849e+00],\n",
      "        [7.6061e+02, 7.9329e+02, 7.9875e+02, 7.9936e+02],\n",
      "        [6.2300e+00, 7.8778e+02, 1.8970e+02, 7.9996e+02],\n",
      "        [6.6935e-01, 3.9457e+02, 3.2331e+00, 7.9024e+02],\n",
      "        [4.1005e+02, 5.1119e+02, 5.5375e+02, 6.8583e+02],\n",
      "        [7.8177e+02, 5.7053e+02, 7.9896e+02, 7.9245e+02],\n",
      "        [6.3917e+02, 7.7824e+02, 7.9368e+02, 7.9836e+02],\n",
      "        [1.5352e+00, 6.1258e+02, 3.3432e+01, 8.0000e+02],\n",
      "        [7.4187e+02, 6.4321e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [7.6773e+02, 7.9533e+02, 7.9640e+02, 7.9991e+02],\n",
      "        [2.5955e-01, 6.9304e+02, 5.1385e+00, 7.8774e+02],\n",
      "        [1.9406e+02, 3.6148e+02, 2.7263e+02, 4.4200e+02],\n",
      "        [2.2058e+02, 4.3662e+02, 4.9969e+02, 7.9342e+02],\n",
      "        [7.1126e+02, 7.7063e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [2.5219e+02, 7.9763e+02, 5.5639e+02, 8.0000e+02],\n",
      "        [2.0377e+02, 6.5182e+02, 3.4661e+02, 7.7426e+02],\n",
      "        [1.6358e+02, 3.4398e+02, 2.7306e+02, 4.7028e+02],\n",
      "        [7.1346e+02, 7.9296e+02, 8.0000e+02, 7.9933e+02],\n",
      "        [1.1601e+02, 3.3517e+02, 3.6730e+02, 6.5931e+02],\n",
      "        [5.1578e-01, 7.6483e+02, 8.2062e+00, 7.9280e+02],\n",
      "        [4.2714e+02, 4.3383e+02, 5.6084e+02, 4.8779e+02],\n",
      "        [2.9942e-01, 7.6799e+02, 4.8474e+00, 7.8774e+02],\n",
      "        [1.8650e+02, 4.3855e+02, 3.6689e+02, 7.8557e+02],\n",
      "        [4.0975e+02, 0.0000e+00, 8.0000e+02, 2.5049e+01],\n",
      "        [6.6753e+00, 5.5831e+02, 1.9624e+02, 7.7672e+02],\n",
      "        [7.9034e+02, 5.5974e+01, 7.9985e+02, 6.8940e+02],\n",
      "        [6.6343e+02, 0.0000e+00, 8.0000e+02, 8.0000e+02],\n",
      "        [4.8263e+02, 7.7240e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [7.8785e+02, 3.7651e+02, 7.9994e+02, 8.0000e+02],\n",
      "        [1.1581e+02, 9.1055e+01, 3.0851e+02, 7.1698e+02],\n",
      "        [4.4458e+02, 7.8759e+02, 8.0000e+02, 7.9936e+02],\n",
      "        [5.4367e+00, 7.9505e+02, 1.5529e+02, 7.9976e+02],\n",
      "        [3.0598e+02, 5.3092e+02, 5.4735e+02, 7.8258e+02],\n",
      "        [3.0030e+02, 7.2023e+02, 3.5616e+02, 7.7353e+02],\n",
      "        [9.9604e+01, 4.4969e+02, 5.7667e+02, 6.3696e+02],\n",
      "        [2.1133e+02, 4.9419e+02, 3.1153e+02, 7.7759e+02],\n",
      "        [6.6217e+02, 7.8686e+02, 8.0000e+02, 8.0000e+02],\n",
      "        [8.1073e+00, 7.7239e+02, 3.3358e+02, 7.9966e+02],\n",
      "        [3.3076e+02, 4.3480e+02, 6.4911e+02, 6.0925e+02],\n",
      "        [7.8821e+02, 0.0000e+00, 7.9968e+02, 3.6881e+02],\n",
      "        [7.6482e+00, 0.0000e+00, 2.2454e+02, 8.0000e+02],\n",
      "        [8.2080e+01, 5.4066e+02, 1.8750e+02, 7.6226e+02],\n",
      "        [1.9566e+02, 7.8548e+02, 6.5012e+02, 7.9700e+02],\n",
      "        [1.8457e+00, 1.9989e+02, 3.5657e+01, 8.0000e+02],\n",
      "        [1.6534e+01, 3.4432e+00, 2.2181e+02, 2.4804e+01]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.5816, 0.5802, 0.5769, 0.4777, 0.4686, 0.4649, 0.4620, 0.4606, 0.4570,\n",
      "        0.4561, 0.4545, 0.4388, 0.4388, 0.4364, 0.4323, 0.4321, 0.4227, 0.4217,\n",
      "        0.4214, 0.4200, 0.4178, 0.4154, 0.4137, 0.4046, 0.4034, 0.4030, 0.3947,\n",
      "        0.3905, 0.3898, 0.3885, 0.3881, 0.3844, 0.3834, 0.3809, 0.3808, 0.3803,\n",
      "        0.3799, 0.3792, 0.3785, 0.3761, 0.3758, 0.3751, 0.3745, 0.3740, 0.3735,\n",
      "        0.3721, 0.3711, 0.3701, 0.3699, 0.3670, 0.3667, 0.3655, 0.3649, 0.3631,\n",
      "        0.3622, 0.3610, 0.3593, 0.3583, 0.3575, 0.3563, 0.3541, 0.3540, 0.3540,\n",
      "        0.3537, 0.3529, 0.3527, 0.3510, 0.3508, 0.3492, 0.3486, 0.3437, 0.3421,\n",
      "        0.3401, 0.3391, 0.3384, 0.3375, 0.3373, 0.3365, 0.3364, 0.3352, 0.3323,\n",
      "        0.3315, 0.3303, 0.3302, 0.3302, 0.3301, 0.3300, 0.3288, 0.3274, 0.3263,\n",
      "        0.3259, 0.3258, 0.3257, 0.3256, 0.3252, 0.3250, 0.3245, 0.3218, 0.3208,\n",
      "        0.3207])}]\n",
      "type(pred_boxes[i])=<class 'dict'>\n",
      "type(pred_boxes[i])=<class 'dict'>\n",
      "type(pred_boxes[i])=<class 'dict'>\n",
      "type(pred_boxes[i])=<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769f06ce3914452192d11c082952062d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c681948645345d4b309145829ab5e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gentle-firebrand-34</strong> at: <a href='https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/acbwuod3' target=\"_blank\">https://wandb.ai/hidden-layer-cake/hlc-polyp-detection/runs/acbwuod3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230502_174317-acbwuod3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index is out of bounds for dimension with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mif\u001b[39;00m run \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     run\u001b[39m.\u001b[39mwatch(model)\n\u001b[0;32m----> 7\u001b[0m trained_model \u001b[39m=\u001b[39m train_model(model, run_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhead\u001b[39;49m\u001b[39m\"\u001b[39;49m, dm\u001b[39m=\u001b[39;49mpolyp_dm, run\u001b[39m=\u001b[39;49mrun)\n\u001b[1;32m      9\u001b[0m model\u001b[39m.\u001b[39mfull_train()\n\u001b[1;32m     10\u001b[0m model \u001b[39m=\u001b[39m train_model(model, run_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m\"\u001b[39m, dm\u001b[39m=\u001b[39mpolyp_dm, run\u001b[39m=\u001b[39mrun)\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, run_name, dm, run)\u001b[0m\n\u001b[1;32m     12\u001b[0m chkpt \u001b[39m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     13\u001b[0m     dirpath\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(MODEL_DIR, \u001b[39m\"\u001b[39m\u001b[39mcheckpoints\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     14\u001b[0m     filename\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mchkpt-\u001b[39m\u001b[39m{\u001b[39;00mrun_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_recall\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(gpus\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, logger\u001b[39m=\u001b[39mwandb_logger, callbacks\u001b[39m=\u001b[39m[chkpt]) \u001b[39mif\u001b[39;00m DEVICE \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m Trainer(accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m, logger\u001b[39m=\u001b[39mwandb_logger, callbacks\u001b[39m=\u001b[39m[chkpt])\n\u001b[0;32m---> 19\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     20\u001b[0m     model,\n\u001b[1;32m     21\u001b[0m     datamodule\u001b[39m=\u001b[39;49mdm)\n\u001b[1;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m LightningFasterModule\u001b[39m.\u001b[39mload_from_checkpoint(chkpt\u001b[39m.\u001b[39mbest_model_path)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    609\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    610\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    644\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    645\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    646\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    648\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    649\u001b[0m )\n\u001b[0;32m--> 650\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    652\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1112\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1114\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1191\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1214\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:267\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(dataloader, batch_to_device\u001b[39m=\u001b[39mbatch_to_device)\n\u001b[1;32m    266\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 267\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:213\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    212\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 213\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_loop\u001b[39m.\u001b[39;49mrun(kwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    217\u001b[0m \u001b[39m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py:88\u001b[0m, in \u001b[0;36mTrainingBatchLoop.advance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[1;32m     85\u001b[0m     optimizers \u001b[39m=\u001b[39m _get_active_optimizers(\n\u001b[1;32m     86\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizer_frequencies, kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbatch_idx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m     87\u001b[0m     )\n\u001b[0;32m---> 88\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_loop\u001b[39m.\u001b[39;49mrun(optimizers, kwargs)\n\u001b[1;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_loop\u001b[39m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:202\u001b[0m, in \u001b[0;36mOptimizerLoop.advance\u001b[0;34m(self, optimizers, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madvance\u001b[39m(\u001b[39mself\u001b[39m, optimizers: List[Tuple[\u001b[39mint\u001b[39m, Optimizer]], kwargs: OrderedDict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_kwargs(kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_idx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hiddens)\n\u001b[0;32m--> 202\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_optimization(kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizers[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptim_progress\u001b[39m.\u001b[39;49moptimizer_position])\n\u001b[1;32m    203\u001b[0m     \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m         \u001b[39m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[39;00m\n\u001b[1;32m    205\u001b[0m         \u001b[39m# would be skipped otherwise\u001b[39;00m\n\u001b[1;32m    206\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_idx] \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39masdict()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:249\u001b[0m, in \u001b[0;36mOptimizerLoop._run_optimization\u001b[0;34m(self, kwargs, optimizer)\u001b[0m\n\u001b[1;32m    241\u001b[0m         closure()\n\u001b[1;32m    243\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[39m# the `batch_idx` is optional with inter-batch parallelism\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(optimizer, opt_idx, kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[1;32m    251\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[1;32m    253\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     \u001b[39m# if no result, user decided to skip optimization\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     \u001b[39m# otherwise update running loss + reset accumulated loss\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[39m# TODO: find proper way to handle updating running loss\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:370\u001b[0m, in \u001b[0;36mOptimizerLoop._optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    362\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe NVIDIA/apex AMP implementation has been deprecated upstream. Consequently, its integration inside\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m PyTorch Lightning has been deprecated in v1.9.0 and will be removed in v2.0.0.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m return True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m     )\n\u001b[1;32m    369\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39musing_native_amp\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprecision_plugin, MixedPrecisionPlugin)\n\u001b[0;32m--> 370\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[1;32m    371\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    372\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[1;32m    373\u001b[0m     batch_idx,\n\u001b[1;32m    374\u001b[0m     optimizer,\n\u001b[1;32m    375\u001b[0m     opt_idx,\n\u001b[1;32m    376\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    377\u001b[0m     on_tpu\u001b[39m=\u001b[39;49m\u001b[39misinstance\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49maccelerator, TPUAccelerator),\n\u001b[1;32m    378\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    379\u001b[0m     using_lbfgs\u001b[39m=\u001b[39;49mis_lbfgs,\n\u001b[1;32m    380\u001b[0m )\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    383\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1356\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m   1355\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1356\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1358\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1742\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_lbfgs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[1;32m   1664\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1665\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1671\u001b[0m     using_lbfgs: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1672\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1673\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1674\u001b[0m \u001b[39m    Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1675\u001b[0m \u001b[39m    each optimizer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1740\u001b[0m \n\u001b[1;32m   1741\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1742\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:169\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_idx, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[1;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:234\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[0;32m--> 234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(\n\u001b[1;32m    235\u001b[0m     optimizer, model\u001b[39m=\u001b[39;49mmodel, optimizer_idx\u001b[39m=\u001b[39;49mopt_idx, closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    236\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:119\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, optimizer, model, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, optimizer_idx, closure)\n\u001b[0;32m--> 119\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/torch/optim/sgd.py:67\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m---> 67\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m     69\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m     70\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:105\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[1;32m     93\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     94\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m     98\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     99\u001b[0m     \u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[1;32m    102\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    106\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer, optimizer_idx)\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:149\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 149\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    150\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:135\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 135\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_fn()\n\u001b[1;32m    137\u001b[0m     \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:419\u001b[0m, in \u001b[0;36mOptimizerLoop._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[1;32m    412\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m    A ``ClosureResult`` containing the training step output.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m training_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    420\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()\n\u001b[1;32m    422\u001b[0m model_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39m\"\u001b[39m\u001b[39mtraining_step_end\u001b[39m\u001b[39m\"\u001b[39m, training_step_output)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1494\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1494\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1496\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:378\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[1;32m    377\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TrainingStep)\n\u001b[0;32m--> 378\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/CSCI 566 - Deep Learning and Its Applications/HLC - 566 Project/hlc-polyp-detection/LightningFasterRCNN/src/LightningFasterModule.py:21\u001b[0m, in \u001b[0;36mflush_and_gc.<locals>.g\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m     20\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m---> 21\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/CSCI 566 - Deep Learning and Its Applications/HLC - 566 Project/hlc-polyp-detection/LightningFasterRCNN/src/LightningFasterModule.py:88\u001b[0m, in \u001b[0;36mLightningFasterModule.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     84\u001b[0m images, targets \u001b[39m=\u001b[39m batch\n\u001b[1;32m     85\u001b[0m \u001b[39m# targets = [{k: v for k, v in t.items()} for t in targets]\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[39m# fasterrcnn takes both images and targets for training, returns\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m loss_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdetector(images, targets)\n\u001b[1;32m     90\u001b[0m pred_boxes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(images)\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetector\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/torchvision/models/detection/generalized_rcnn.py:105\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    103\u001b[0m     features \u001b[39m=\u001b[39m OrderedDict([(\u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m, features)])\n\u001b[1;32m    104\u001b[0m proposals, proposal_losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrpn(images, features, targets)\n\u001b[0;32m--> 105\u001b[0m detections, detector_losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroi_heads(features, proposals, images\u001b[39m.\u001b[39;49mimage_sizes, targets)\n\u001b[1;32m    106\u001b[0m detections \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mpostprocess(detections, images\u001b[39m.\u001b[39mimage_sizes, original_image_sizes)  \u001b[39m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m    108\u001b[0m losses \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/torchvision/models/detection/roi_heads.py:755\u001b[0m, in \u001b[0;36mRoIHeads.forward\u001b[0;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtarget keypoints must of float type, instead got \u001b[39m\u001b[39m{\u001b[39;00mt[\u001b[39m'\u001b[39m\u001b[39mkeypoints\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    754\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m--> 755\u001b[0m     proposals, matched_idxs, labels, regression_targets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselect_training_samples(proposals, targets)\n\u001b[1;32m    756\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    757\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/torchvision/models/detection/roi_heads.py:649\u001b[0m, in \u001b[0;36mRoIHeads.select_training_samples\u001b[0;34m(self, proposals, targets)\u001b[0m\n\u001b[1;32m    646\u001b[0m proposals \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_gt_proposals(proposals, gt_boxes)\n\u001b[1;32m    648\u001b[0m \u001b[39m# get matching gt indices for each proposal\u001b[39;00m\n\u001b[0;32m--> 649\u001b[0m matched_idxs, labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massign_targets_to_proposals(proposals, gt_boxes, gt_labels)\n\u001b[1;32m    650\u001b[0m \u001b[39m# sample a fixed proportion of positive-negative proposals\u001b[39;00m\n\u001b[1;32m    651\u001b[0m sampled_inds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubsample(labels)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bolt-hlc/lib/python3.10/site-packages/torchvision/models/detection/roi_heads.py:588\u001b[0m, in \u001b[0;36mRoIHeads.assign_targets_to_proposals\u001b[0;34m(self, proposals, gt_boxes, gt_labels)\u001b[0m\n\u001b[1;32m    584\u001b[0m matched_idxs_in_image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproposal_matcher(match_quality_matrix)\n\u001b[1;32m    586\u001b[0m clamped_matched_idxs_in_image \u001b[39m=\u001b[39m matched_idxs_in_image\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 588\u001b[0m labels_in_image \u001b[39m=\u001b[39m gt_labels_in_image[clamped_matched_idxs_in_image]\n\u001b[1;32m    589\u001b[0m labels_in_image \u001b[39m=\u001b[39m labels_in_image\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\n\u001b[1;32m    591\u001b[0m \u001b[39m# Label background (below the low threshold)\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index is out of bounds for dimension with size 0"
     ]
    }
   ],
   "source": [
    "from src.LightningFasterModule import LightningFasterModule\n",
    "\n",
    "with wandb_context() as run:\n",
    "    model = LightningFasterModule(CONFIG)\n",
    "    if run is not None:\n",
    "        run.watch(model)\n",
    "    trained_model = train_model(model, run_name=\"head\", dm=polyp_dm, run=run)\n",
    "\n",
    "    model.full_train()\n",
    "    model = train_model(model, run_name=\"full\", dm=polyp_dm, run=run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hidden-layer-cake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
