{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "\n",
    "from src.config import DEVICE, NUM_CLASSES, NUM_EPOCHS, OUTPUT_DIR\n",
    "from src.config import VISUALIZE_AFTER_TRANSFORM, SAVE_PLOTS_EPOCH, SAVE_MODEL_EPOCH\n",
    "from src.model import create_model\n",
    "from src.utils import Averager\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from src.PolypDataset import get_dataloaders\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "# from engine import train, validate\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m MODEL_NAME \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpolyps_model_1\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[39m# Get the dataloaders\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m train_loader, valid_loader \u001b[39m=\u001b[39m get_dataloaders()\n\u001b[1;32m     27\u001b[0m \u001b[39m# Show transformed images if VISUALIZE_AFTER_TRANSFORM is True\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m# TODO: Don't use this until we have rewritten the show_transformed_images function\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m# to work with pyplot instead of cv2\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mif\u001b[39;00m VISUALIZE_AFTER_TRANSFORM:\n",
      "File \u001b[0;32m~/Desktop/CSCI 566 - Deep Learning and Its Applications/HLC - 566 Project/hidden-layer-cake/FasterRCNN/src/PolypDataset.py:136\u001b[0m, in \u001b[0;36mget_dataloaders\u001b[0;34m(batch_size, resize_to, num_workers)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39mReturns: train_loader, valid_loader\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m\"\"\"\u001b[39;00m    \n\u001b[1;32m    135\u001b[0m train_dataset \u001b[39m=\u001b[39m PolypDataset(TRAIN_DIR, resize_to, resize_to, CLASSES, get_transform(train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m--> 136\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m    137\u001b[0m     train_dataset, \n\u001b[1;32m    138\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m    139\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    140\u001b[0m     num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    141\u001b[0m     pin_memory\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    142\u001b[0m     drop_last\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m    143\u001b[0m     collate_fn\u001b[39m=\u001b[39;49mcollate_fn\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    145\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain dataset size: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(train_dataset)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m \u001b[39m# Create the validation dataset\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/site-packages/torch/utils/data/dataloader.py:344\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 344\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    345\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/site-packages/torch/utils/data/sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mreplacement=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement))\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mvalue, but got num_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples))\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# Initialize the model and move to GPU (if available)\n",
    "model = create_model(num_classes=NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Obtain model parameters to be optimized/updated in this run.\n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "\n",
    "# Define the optimizer\n",
    "# TODO: Try out alternatives to SGD --> Maybe use the ABC algorithm \n",
    "optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Initialize training loss tracking variables for plotting\n",
    "train_loss_hist = Averager()\n",
    "train_iter = 1\n",
    "train_losses = []\n",
    "# Initialize validation loss tracking variables for plotting\n",
    "val_loss_hist = Averager()\n",
    "val_iter = 1\n",
    "val_losses = []\n",
    "\n",
    "# Give the model a name :-)\n",
    "MODEL_NAME = 'polyps_model_1'\n",
    "\n",
    "# Get the dataloaders\n",
    "train_loader, valid_loader = get_dataloaders()\n",
    "\n",
    "# Show transformed images if VISUALIZE_AFTER_TRANSFORM is True\n",
    "# TODO: Don't use this until we have rewritten the show_transformed_images function\n",
    "# to work with pyplot instead of cv2\n",
    "if VISUALIZE_AFTER_TRANSFORM:\n",
    "    from src.utils import show_transformed_image\n",
    "    show_transformed_image(train_loader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training loop function\n",
    "def train(train_data_loader, model):\n",
    "    print('Training...')\n",
    "    global train_iter\n",
    "    global train_losses\n",
    "\n",
    "    # THE LOOP w/Beautiful progress bar\n",
    "    # print(f'{len(train_data_loader)=}')\n",
    "    with tqdm(train_data_loader, total=len(train_data_loader)) as pbar:\n",
    "        for data in pbar:\n",
    "            # Get the images and targets from the data loader\n",
    "            images, targets = data\n",
    "\n",
    "            # Move the images and targets to the GPU\n",
    "            images = list(image.to(DEVICE) for image in images)\n",
    "            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            loss_dict = model(images, targets)\n",
    "\n",
    "            # Get the loss\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            # Backward pass\n",
    "            losses.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the progress bar\n",
    "            if train_iter % 100 == 0:\n",
    "                pbar.set_postfix(loss=losses.item())\n",
    "            \n",
    "            # Update the losses\n",
    "            train_loss_hist.send(losses.item())\n",
    "            train_iter += 1\n",
    "\n",
    "    return train_losses \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The validation loop function\n",
    "def validate(val_data_loader, model):\n",
    "    print('Validating...')\n",
    "    global val_iter\n",
    "    global val_losses\n",
    "\n",
    "    # THE LOOP w/Beautiful progress bar\n",
    "    with tqdm(val_data_loader, total=len(val_data_loader)) as pbar:\n",
    "        for data in pbar:\n",
    "            # Get the images and targets from the data loader\n",
    "            images, targets = data\n",
    "\n",
    "            # Move the images and targets to the GPU\n",
    "            images = list(image.to(DEVICE) for image in images)\n",
    "            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # Forward pass\n",
    "            with torch.no_grad():\n",
    "                loss_dict = model(images, targets)\n",
    "\n",
    "            # Get the loss\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            val_losses = losses.item()\n",
    "    \n",
    "\n",
    "            # Update the progress bar\n",
    "            if val_iter % 100 == 0:\n",
    "                pbar.set_postfix(loss=losses.item())\n",
    "\n",
    "\n",
    "            # Update the losses\n",
    "            val_loss_hist.send(losses.item())\n",
    "            val_iter += 1\n",
    "\n",
    "    return val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22983081c86946e3a514f8a83a201cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/899 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Process Process-5:\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Users/jarret/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     16\u001b[0m \u001b[39m# The training loop\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m train_losses \u001b[39m=\u001b[39m train(train_loader, model)\n\u001b[1;32m     19\u001b[0m \u001b[39m# The validation loop\u001b[39;00m\n\u001b[1;32m     20\u001b[0m val_losses \u001b[39m=\u001b[39m validate(valid_loader, model)\n",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_data_loader, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# THE LOOP w/Beautiful progress bar\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# print(f'{len(train_data_loader)=}')\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(train_data_loader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_data_loader)) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mfor\u001b[39;00m _, data \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m     11\u001b[0m         \u001b[39m# Get the images and targets from the data loader\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         images, targets \u001b[39m=\u001b[39m data\n\u001b[1;32m     14\u001b[0m         \u001b[39m# Move the images and targets to the GPU\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/site-packages/tqdm/notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    260\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    262\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hidden-layer-cake/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The MAIN Training Loop\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f'Epoch {epoch}/{NUM_EPOCHS}')\n",
    "\n",
    "    # Reset training and validation loss histories\n",
    "    train_loss_hist.reset()\n",
    "    val_loss_hist.reset()\n",
    "\n",
    "    # Prepare training and validation plots:\n",
    "    figure_1, train_ax = plt.subplots()\n",
    "    figure_2, val_ax = plt.subplots()\n",
    "\n",
    "    # Start the timer and begin training and validation\n",
    "    start = time.time()\n",
    "\n",
    "    # The training loop\n",
    "    train_losses = train(train_loader, model)\n",
    "\n",
    "    # The validation loop\n",
    "    val_losses = validate(valid_loader, model)\n",
    "\n",
    "    # Print the training and validation loss\n",
    "    print(f'Epoch {epoch} train loss: {train_loss_hist.value:.3f} val loss: {val_loss_hist.value:.3f}')\n",
    "    end = time.time()\n",
    "    print(f'Training time: {((end - start) / 60):.3f}min for {train_iter} iterations')\n",
    "\n",
    "\n",
    "    if (epoch % SAVE_MODEL_EPOCH == 0) or (epoch == NUM_EPOCHS):\n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR,f'model{epoch}.pth'))\n",
    "        print(f'Saved model to {os.path.join(OUTPUT_DIR,f\"model{epoch}.pth\")}')\n",
    "    \n",
    "    if (epoch % SAVE_PLOTS_EPOCH == 0) or (epoch == NUM_EPOCHS):\n",
    "        # Generate plots\n",
    "        train_ax.plot(train_losses, color='blue')\n",
    "        train_ax.set_xlabel('Iterations')\n",
    "        train_ax.set_ylabel('Training Loss')\n",
    "        val_ax.plot(val_losses, color='red')\n",
    "        val_ax.set_xlabel('Iterations')\n",
    "        val_ax.set_ylabel('Validation Loss')\n",
    "        figure_1.savefig(os.path.join(OUTPUT_DIR,f'train_loss{epoch}.png'))\n",
    "        figure_2.savefig(os.path.join(OUTPUT_DIR,f'val_loss{epoch}.png'))\n",
    "        print(f'Saved plots to {os.path.join(OUTPUT_DIR,f\"[train or val]_loss{epoch}.png\")}')\n",
    "\n",
    "    plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hidden-layer-cake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7b478c88c3c92326b123abcbaa45e1253bd2eebcb79c347190332c1d725b08d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
